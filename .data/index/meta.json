[{"path": ".data\\docs\\try.md", "chunk_id": 0, "text": "# The Fuck [![Version][version-badge]][version-link] [![Build Status][workflow-badge]][workflow-link] [![Coverage][coverage-badge]][coverage-link] [![MIT License][license-badge]](LICENSE.md)\n\n*The Fuc"}, {"path": ".data\\docs\\try.md", "chunk_id": 1, "text": ":\n\n```bash\n➜ apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\n➜ fuck\nsu"}, {"path": ".data\\docs\\try.md", "chunk_id": 2, "text": "ing objects: 9, done.\n...\n```\n\n```bash\n➜ puthon\nNo command 'puthon' found, did you mean:\n Command 'python' from package 'python-minimal' (main)\n Command 'python' from package 'python3' (main)\nzsh: com"}, {"path": ".data\\docs\\try.md", "chunk_id": 3, "text": "➜ fuck\nlein repl [enter/↑/↓/ctrl+c]\nnREPL server started on port 54848 on host 127.0.0.1 - nrepl://127.0.0.1:54848\nREPL-y 0.3.1\n...\n```\n\nIf you're not afraid of blindly running corrected commands, the"}, {"path": ".data\\docs\\try.md", "chunk_id": 4, "text": "ontents\n\n1. [Requirements](#requirements)\n2. [Installations](#installation)\n3. [Updating](#updating)\n4. [How it works](#how-it-works)\n5. [Creating your own rules](#creating-your-own-rules)\n6. [Setting"}, {"path": ".data\\docs\\try.md", "chunk_id": 5, "text": "Homebrew][homebrew]:\n\n```bash\nbrew install thefuck\n```\n\nOn Ubuntu / Mint, install *The Fuck* with the following commands:\n```bash\nsudo apt update\nsudo apt install python3-dev python3-pip python3-setup"}, {"path": ".data\\docs\\try.md", "chunk_id": 6, "text": "sudo pacman -S thefuck\n```\n\nOn other systems, install *The Fuck*  by using `pip`:\n\n```bash\npip install thefuck\n```\n\n[Alternatively, you may use an OS package manager (OS X, Ubuntu, Arch).](https://git"}, {"path": ".data\\docs\\try.md", "chunk_id": 7, "text": "ur shell config (Bash, Zsh, Fish, Powershell, tcsh).](https://github.com/nvbn/thefuck/wiki/Shell-aliases)\n\nChanges are only available in a new shell session. To make changes immediately\navailable, run"}, {"path": ".data\\docs\\try.md", "chunk_id": 8, "text": "dating\n\n```bash\npip3 install thefuck --upgrade\n```\n\n**Note: Alias functionality was changed in v1.34 of *The Fuck***\n\n## Uninstall\n\nTo remove *The Fuck*, reverse the installation process:\n- erase or c"}, {"path": ".data\\docs\\try.md", "chunk_id": 9, "text": "enabled by default:\n\n* `adb_unknown_command` &ndash; fixes misspelled commands like `adb logcta`;\n* `ag_literal` &ndash; adds `-Q` to `ag` when suggested;\n* `aws_cli` &ndash; fixes misspelled commands"}, {"path": ".data\\docs\\try.md", "chunk_id": 10, "text": "ommands;\n* `cd_cs` &ndash; changes `cs` to `cd`;\n* `cd_mkdir` &ndash; creates directories before cd'ing into them;\n* `cd_parent` &ndash; changes `cd..` to `cd ..`;\n* `chmod_x` &ndash; adds execution b"}, {"path": ".data\\docs\\try.md", "chunk_id": 11, "text": "directory;\n* `cpp11` &ndash; adds missing `-std=c++11` to `g++` or `clang++`;\n* `dirty_untar` &ndash; fixes `tar x` command that untarred in the current directory;\n* `dirty_unzip` &ndash; fixes `unzip"}, {"path": ".data\\docs\\try.md", "chunk_id": 12, "text": "ash; fixes wrong docker commands like `docker tags`;\n* `docker_image_being_used_by_container` &dash; removes the container that is using the image before removing the image;\n* `dry` &ndash; fixes repe"}, {"path": ".data\\docs\\try.md", "chunk_id": 13, "text": "known to git.\"*;\n* `git_add_force` &ndash; adds `--force` to `git add <pathspec>...` when paths are .gitignore'd;\n* `git_bisect_usage` &ndash; fixes `git bisect strt`, `git bisect goood`, `git bisect "}, {"path": ".data\\docs\\try.md", "chunk_id": 14, "text": "reating a branch that already exists;\n* `git_branch_list` &ndash; catches `git branch list` in place of `git branch` and removes created branch;\n* `git_branch_0flag` &ndash; fixes commands such as `gi"}, {"path": ".data\\docs\\try.md", "chunk_id": 15, "text": " ...` or `git commit -p ...` after previous commit if it failed because nothing was staged;\n* `git_commit_amend` &ndash; offers `git commit --amend` after previous commit;\n* `git_commit_reset` &ndash;"}, {"path": ".data\\docs\\try.md", "chunk_id": 16, "text": "sh; fixes `fatal: bad flag '...' after filename`\n* `git_help_aliased` &ndash; fixes `git help <alias>` commands replacing <alias> with the aliased command;\n* `git_hook_bypass` &ndash; adds `--no-verif"}, {"path": ".data\\docs\\try.md", "chunk_id": 17, "text": "it_not_command` &ndash; fixes wrong git commands like `git brnch`;\n* `git_pull` &ndash; sets upstream before executing previous `git pull`;\n* `git_pull_clone` &ndash; clones instead of pulling when th"}, {"path": ".data\\docs\\try.md", "chunk_id": 18, "text": " pull` when `push` was rejected;\n* `git_push_without_commits` &ndash; creates an initial commit if you forget and only `git add .`, when setting up a new project;\n* `git_rebase_no_changes` &ndash; run"}, {"path": ".data\\docs\\try.md", "chunk_id": 19, "text": "` a directory;\n* `git_rm_staged` &ndash;  adds `-f` or `--cached` when you try to `rm` a file with staged changes\n* `git_rebase_merge_dir` &ndash; offers `git rebase (--continue | --abort | --skip)` o"}, {"path": ".data\\docs\\try.md", "chunk_id": 20, "text": "git_tag_force` &ndash; adds `--force` to `git tag <tagname>` when the tag already exists;\n* `git_two_dashes` &ndash; adds a missing dash to commands like `git commit -amend` or `git rebase -continue`;"}, {"path": ".data\\docs\\try.md", "chunk_id": 21, "text": "r situations like `grep -lir . test`;\n* `grep_recursive` &ndash; adds `-r` when you try to `grep` directory;\n* `grunt_task_not_found` &ndash; fixes misspelled `grunt` commands;\n* `gulp_not_task` &ndas"}, {"path": ".data\\docs\\try.md", "chunk_id": 22, "text": "ory;\n* `hostscli` &ndash; tries to fix `hostscli` usage;\n* `ifconfig_device_not_found` &ndash; fixes wrong device names like `wlan0` to `wlp2s0`;\n* `java` &ndash; removes `.java` extension when runnin"}, {"path": ".data\\docs\\try.md", "chunk_id": 23, "text": "&ndash; fixes `ln -s` arguments order;\n* `ls_all` &ndash; adds `-A` to `ls` when output is empty;\n* `ls_lah` &ndash; adds `-lah` to `ls`;\n* `man` &ndash; changes manual section;\n* `man_no_space` &ndas"}, {"path": ".data\\docs\\try.md", "chunk_id": 24, "text": "n_lifecycle_phase` &ndash; fixes misspelled life cycle phases with `mvn`;\n* `npm_missing_script` &ndash; fixes `npm` custom script name in `npm run-script <script>`;\n* `npm_run_script` &ndash; adds mi"}, {"path": ".data\\docs\\try.md", "chunk_id": 25, "text": "yenv` and `rbenv` (eg.: `pyenv isntall` or `goenv list`);\n* `open` &ndash; either prepends `http://` to address passed to `open` or creates a new file or directory and passes it to `open`;\n* `pip_inst"}, {"path": ".data\\docs\\try.md", "chunk_id": 26, "text": "* `prove_recursively` &ndash; adds `-r` when called with directory;\n* `python_command` &ndash; prepends `python` when you try to run non-executable/without `./` python script;\n* `python_execute` &ndas"}, {"path": ".data\\docs\\try.md", "chunk_id": 27, "text": "g` &ndash; runs pending migrations;\n* `react_native_command_unrecognized` &ndash; fixes unrecognized `react-native` commands;\n* `remove_shell_prompt_literal` &ndash; removes leading shell prompt symbo"}, {"path": ".data\\docs\\try.md", "chunk_id": 28, "text": "`sed`'s `s` commands;\n* `sl_ls` &ndash; changes `sl` to `ls`;\n* `ssh_known_hosts` &ndash; removes host from `known_hosts` on warning;\n* `sudo` &ndash; prepends `sudo` to the previous command if it fai"}, {"path": ".data\\docs\\try.md", "chunk_id": 29, "text": "y` &ndash; fixes unrecognized `terraform` commands;\n* `test.py` &ndash; runs `pytest` instead of `test.py`;\n* `touch` &ndash; creates missing directories before \"touching\";\n* `tsuru_login` &ndash; run"}, {"path": ".data\\docs\\try.md", "chunk_id": 30, "text": "mand if a process refuses to run on superuser privilege.\n* `vagrant_up` &ndash; starts up the vagrant instance;\n* `whois` &ndash; fixes `whois` command;\n* `workon_doesnt_exists` &ndash; fixes `virtual"}, {"path": ".data\\docs\\try.md", "chunk_id": 31, "text": "; fixes replaced `yarn` commands;\n* `yarn_help` &ndash; makes it easier to open `yarn` documentation;\n\n##### [Back to Contents](#contents)\n\nThe following rules are enabled by default on specific platf"}, {"path": ".data\\docs\\try.md", "chunk_id": 32, "text": "adable` &ndash; helps you run `apt list --upgradable` after `apt update`;\n* `apt_upgrade` &ndash; helps you run `apt upgrade` after `apt list --upgradable`;\n* `brew_cask_dependency` &ndash; installs c"}, {"path": ".data\\docs\\try.md", "chunk_id": 33, "text": "mand` &ndash; fixes wrong brew commands, for example `brew docto/brew doctor`;\n* `brew_update_formula` &ndash; turns `brew update <formula>` into `brew upgrade <formula>`;\n* `dnf_no_such_command` &nda"}, {"path": ".data\\docs\\try.md", "chunk_id": 34, "text": "`, `pikaur` or `yaourt`.\n* `yum_invalid_operation` &ndash; fixes invalid `yum` calls, like `yum isntall vim`;\n\nThe following commands are bundled with *The Fuck*, but are not enabled by\ndefault:\n\n* `g"}, {"path": ".data\\docs\\try.md", "chunk_id": 35, "text": "functions:\n\n```python\nmatch(command: Command) -> bool\nget_new_command(command: Command) -> str | list[str]\n```\n\nAdditionally, rules can contain optional functions:\n\n```python\nside_effect(old_command: "}, {"path": ".data\\docs\\try.md", "chunk_id": 36, "text": "tings`\n\n`settings` is a special object assembled from `~/.config/thefuck/settings.py`,\nand values from env ([see more below](#settings)).\n\nA simple example rule for running a script with `sudo`:\n\n```p"}, {"path": ".data\\docs\\try.md", "chunk_id": 37, "text": "st, default is 1000\n\nrequires_output = True\n```\n\n[More examples of rules](https://github.com/nvbn/thefuck/tree/master/thefuck/rules),\n[utility functions for rules](https://github.com/nvbn/thefuck/tree"}, {"path": ".data\\docs\\try.md", "chunk_id": 38, "text": "lt `thefuck.const.DEFAULT_RULES`;\n* `exclude_rules` &ndash; list of disabled rules, by default `[]`;\n* `require_confirmation` &ndash; requires confirmation before running new command, by default `True"}, {"path": ".data\\docs\\try.md", "chunk_id": 39, "text": "history commands will be scanned, like `2000`;\n* `alter_history` &ndash; push fixed command to history, by default `True`;\n* `wait_slow_command` &ndash; max amount of time in seconds for getting previ"}, {"path": ".data\\docs\\try.md", "chunk_id": 40, "text": "', 'no_command']\nexclude_rules = ['git_push']\nrequire_confirmation = True\nwait_command = 10\nno_colors = False\npriority = {'sudo': 100, 'no_command': 9999}\ndebug = False\nhistory_limit = 9999\nwait_slow_"}, {"path": ".data\\docs\\try.md", "chunk_id": 41, "text": "before running new command, `true/false`;\n* `THEFUCK_WAIT_COMMAND` &ndash; the max amount of time in seconds for getting previous command output;\n* `THEFUCK_NO_COLORS` &ndash; disable colored output, "}, {"path": ".data\\docs\\try.md", "chunk_id": 42, "text": "history `true/false`;\n* `THEFUCK_WAIT_SLOW_COMMAND` &ndash; the max amount of time in seconds for getting previous command output if it in `slow_commands` list;\n* `THEFUCK_SLOW_COMMANDS` &ndash; list "}, {"path": ".data\\docs\\try.md", "chunk_id": 43, "text": "ush'\nexport THEFUCK_REQUIRE_CONFIRMATION='true'\nexport THEFUCK_WAIT_COMMAND=10\nexport THEFUCK_NO_COLORS='false'\nexport THEFUCK_PRIORITY='no_command=9999:apt_get=100'\nexport THEFUCK_HISTORY_LIMIT='2000"}, {"path": ".data\\docs\\try.md", "chunk_id": 44, "text": "_init__.py\n      *third-party rules*\n    __init__.py\n    *third-party-utils*\n  setup.py\n```\n\n*The Fuck* will find rules located in the `rules` module.\n\n##### [Back to Contents](#contents)\n\n## Experime"}, {"path": ".data\\docs\\try.md", "chunk_id": 45, "text": " 3 with bash or zsh. zsh's autocorrect function also needs to be disabled in order for thefuck to work properly.\n\nTo enable instant mode, add `--enable-experimental-instant-mode`\nto the alias initiali"}, {"path": ".data\\docs\\try.md", "chunk_id": 46, "text": "l=version\n[version-link]:    https://pypi.python.org/pypi/thefuck/\n[workflow-badge]:  https://github.com/nvbn/thefuck/workflows/Tests/badge.svg\n[workflow-link]:   https://github.com/nvbn/thefuck/actio"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 0, "text": "1. Introduction\nWhat is probability theory?\nHow is it related to statistics?\nProbability Theory ̸= Statistics\nThis is similar to how Math ̸= Physics.\nPhysics: Physics uses math to create models of nat"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 1, "text": "tatistics uses these models and data to infer conclusions or make\npredictions.\nExample 1.1: We all throw our hat into the center of the room, and pick one\nback at random. What is the probability that "}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 2, "text": " the data you collect should behave.\nYou now collect data, and from this, infer which hypothesis you believe to be\ntrue.\nProbability theory or statistics?\nAns: Statistics\nSecond Ans: Probability theor"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 3, "text": " the model\nparameter x from the measured data →statistics.\nIn this example, we can also use probability theory to compute the prob. that\nthe estimate is within a tolerance of the true value x, i.e., p"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 4, "text": "history.\nFrom this data, they try to infer what else you might be interested in buying.\nIs this prob. theory or statistics?\nAnswer: Statistics\nExample 1.6: In a room of 100 people, the odds that 2 peo"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 5, "text": "res the position of a rocket car at various\ntimes, and based on this, the car is steered by computer.\nWhat area is this?\nAnswer: Stochastic control.\nExample 1.9: In a digital communication system, you"}, {"path": ".data\\docs\\ECE 203\\01_intro.pdf", "chunk_id": 6, "text": "., reinforcement learning)\n• Stochastic control (e.g., autonomous vehicles, Kalman filter)\n• Digital/wireless communications\n• Statistical signal processing\n• Statistical inference / Detection and est"}, {"path": ".data\\docs\\ECE 203\\02_axioms_of_prob1.pdf", "chunk_id": 0, "text": "2. Axioms (or Laws) of Probability\nSample Space and Events [Ross S2.2]\nRandom experiments do not have predictable outcomes.\nThe set of all possible outcomes is called the sample space, and denoted S\n("}, {"path": ".data\\docs\\ECE 203\\02_axioms_of_prob1.pdf", "chunk_id": 1, "text": " persons will meet. Each will arrive with a delay that is\nbetween 0 and 1 hour:\nS = {(x, y) ∈R2 | 0 ≤x ≤1, 0 ≤y ≤1}.\nDefinition 2.1: A subset E ⊂S is called an event.\n\nExample 2.6: In Example 2.1,\nE ="}, {"path": ".data\\docs\\ECE 203\\02_axioms_of_prob1.pdf", "chunk_id": 2, "text": "thin 1/4 hour of\neach other is:\nE = {(x, y) ∈S\n\f\f |x −y| ≤1/4}\n\nDefinition 2.2: For 2 events E and F:\n• E ∪F\nis the event that either E or F occurs\nE ∪F = {x ∈S |x ∈E or x ∈F}\n• E ∩F\nis the event that"}, {"path": ".data\\docs\\ECE 203\\02_axioms_of_prob1.pdf", "chunk_id": 3, "text": ". , En are said to partition F.\nProperties:\nCommutative Laws:\nE ∪F = F ∪E\nEF = FE\nAssociative Laws:\n(E ∪F) ∪G = E ∪(F ∪G)\n(EF)G = E(FG)\nDistributive Laws:\n(E ∪F)G = EG ∪FG\nEF ∪G =\n(E ∪G)(F ∪G)\n\nExampl"}, {"path": ".data\\docs\\ECE 203\\02_axioms_of_prob1.pdf", "chunk_id": 4, "text": "ow ∩iEc\ni ⊂(∪iEi)c\nLet x ∈∩iEc\ni\nThen, for each i, x ∈Ec\ni\nThen, for each i, x /∈Ei\nThen, x /∈E1 ∪E2 ∪· · · ∪En\nThen, x ∈(E1 ∪E2 ∪· · · ∪En)c\n|\n{z\n}\n(∪iEi)c\nHome Exercises: Verify other properties wit"}, {"path": ".data\\docs\\ECE 203\\03_axioms_of_prob2.pdf", "chunk_id": 0, "text": "3. Axioms (or Laws) of Probability\n[Ross S2.3, S2.4]\nWe wish to assign to each event E a probability, denoted P[E] (or P(E)).\nHow do we determine it?\nFrequentist approach: Let n(E) be number of occure"}, {"path": ".data\\docs\\ECE 203\\03_axioms_of_prob2.pdf", "chunk_id": 1, "text": "P[∅] = 0.\n\nWhy? Let E1 = S, E2 = ∅, E3 = ∅, . . ..\nThen E1, E2, E3, . . . are disjoint.\nHence,\nP[E1 ∪E2 ∪E3 ∪· · · ] = P[E1] + P[E2] + P[E3] + · · ·\n= P[S] + P[∅] + P[∅] + · · ·\n= 1 + P[∅] + P[∅] + · "}, {"path": ".data\\docs\\ECE 203\\03_axioms_of_prob2.pdf", "chunk_id": 2, "text": "1] · · · = P[36]\n2)\n1 = P[{00, 0, 1, · · · , 36}] = P[00] + P[0] + · · · + P[36]\nHence,\nP[00] = P[0] = · · · = P[36] = 1/38\nSo,\nP[even] = P[{2, 4, . . . , 36}]\n= P[2] + P[4] + · · · + P[36]\n= 18/38 = "}, {"path": ".data\\docs\\ECE 203\\03_axioms_of_prob2.pdf", "chunk_id": 3, "text": "z }\n9/19\n≤P[evenc]\n|\n{z\n}\n10/19\nCorollary 3.5 P[E ∪F] = P[E] + P[F] −P[E ∩F]\nWhy?\nP[E] + P[F] = P[I ∪II] + P[II ∪III]\n= P[I] + P[II] + P[II] + P[III]\n= P[I ∪II ∪III] + P[II]\n= P[E ∪F] + P[EF]\nExample "}, {"path": ".data\\docs\\ECE 203\\03_axioms_of_prob2.pdf", "chunk_id": 4, "text": "ralize the P[E ∪F] idea of Corollary 3.5? Yes!\nP[E ∪F ∪G] = P[(E ∪F) ∪G]\n= P[(E ∪F)] + P[G] −P[(E ∪F)G]\n= P[E] + P[F] −P[EF] + P[G] −P[EG ∪FG]\n= P[E] + P[F] + P[G] −P[EF]\n−(P[EG] + P[FG] −P[EGFG])\n= P"}, {"path": ".data\\docs\\ECE 203\\04_axioms_of_prob3.pdf", "chunk_id": 0, "text": "4. Sample Spaces with Equally Likely Outcomes\n[Ross S2.5]\nSay S = {1, 2, . . . N}.\nThen\n1 = P[S] = P[1] + P[2] + · · · + P[N].\n(4.1)\nIf each outcome is equally likely:\nP[1] = P[2] = · · · = P[N]\n(4.2)"}, {"path": ".data\\docs\\ECE 203\\04_axioms_of_prob3.pdf", "chunk_id": 1, "text": "order of the dice rolls matter. If we don’t consider the\norder, is each pair still equally likely?\n\nExample 4.2: An urn has 7 white balls and 5 black balls.\nIf we draw 3 balls at random, what is the p"}, {"path": ".data\\docs\\ECE 203\\04_axioms_of_prob3.pdf", "chunk_id": 2, "text": "5 × 7 × (5 −1) ways.\nCase 3: 3rd ball is white; there are 5 × (5 −1) × 7 ways.\n⇒\n|E2| = 7 × 5 × 4 × 3\nprob = |E2|\n|S2| = 7/22\nThese problems all boil down to counting combinations. I’ll assume you\nlea"}, {"path": ".data\\docs\\ECE 203\\04_axioms_of_prob3.pdf", "chunk_id": 3, "text": "e n × (n −1) × · · · × 1 = n! possible hat assignments.\nLet Ei = {person i selects hat # i}.\nP[E1 ∪E2 ∪· · · ∪En]\n= P[E1] + P[E2] + · · · P[En]\n−\nX\ni1<i2\nP[Ei1Ei2]\n...\n+ (−1)m+1\nX\ni1<···<im\nP[Ei1Ei2 ·"}, {"path": ".data\\docs\\ECE 203\\04_axioms_of_prob3.pdf", "chunk_id": 4, "text": "\u0013(n −m)!\nn!\n=\nn!\n(n −m)!m!\n(n −m)!\nn!\n= 1\nm!\n⇒\nP[E1 ∪E2 ∪· · · ∪En] = 1\n1! −1\n2! + 1\n3! + · · · + (−1)n+1\nn!\nP[Ec\n1Ec\n2 · · · Ec\nn] = 1 −P[E1 ∪E2 ∪· · · ∪En]\n= 1 −1 + 1\n2! −1\n3! + · · · + (−1)n\nn!\nThi"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 0, "text": "5. Conditional Probability and Independence\nConditional Probability [Ross S3.1, S3.2]\nConditional probability is one of the most important concepts in this course.\n• it is a tool to compute probabilit"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 1, "text": "utcomes given this new information are:\nF = {(4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6)}.\nThe other 30 cases are inconsistent with the 1st die roll\n⇒they now have probability = 0.\nThe 6 cases in F"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 2, "text": "F] = 1/6.\nLet’s generalize: let’s not assume the elements of S are equally likely:\nIf F has occured, then for E to occur, EF must occur.\nIf F has occured, our sample space S is reduced to F.\nSo if F h"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 3, "text": "\nP[F] = 1/4\n1/2 = 1/2.\nb) Here, F = {hh, ht, th}. So\nP[E|F] = P[EF]\nP[F] = 1/4\n3/4 = 1/3.\nExample 5.4: Two 4-sided dice are rolled. Let\nE = { max of both rolls is 3}\nF = { min of both rolls is 2}\nWhat"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 4, "text": "[F] ≤1\nsince EF ⊂F\n[A2]\nP[S|F] = P[SF]/P[F] = P[F]/P[F] = 1.\n[A3]\nLet E1 ∩E2 = 0. Then E1F ∩E2F = 0.\nP[E1 ∪E2|F] = P[(E1 ∪E2)F]/P[F]\n= P[E1F ∪E2F]/P[F]\n= P[E1F]/P[F] + P[E2F]/P[F]\n= P[E1|F] + P[E2|F]\n"}, {"path": ".data\\docs\\ECE 203\\05_cond_prob1.pdf", "chunk_id": 5, "text": "vided into 3\ngroups of 5. What is the prob that each group has exactly 1 grad student?\nSolution:\nLet\nE1 = {grad #1 is in a group},\nE2 = {grad #1 and #2 are in different groups}\nE3 = {all grads are in "}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 0, "text": "6. Conditional Probability and Independence\nBaye’s Theorem [Ross S3.3]\nLaw of Total Probability:\nLet E, F ⊂S.\nThen\nE =ES = E(F ∪F c) = EF ∪EF c\nand\nP[E] = P[EF] + P[EF c]\n= P[E|F]P[F] + P[E|F c]P[F c]"}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 1, "text": "S.\nThen\nE = ES = E\n n\n[\ni=1\nFi\n!\n=\nn\n[\ni=1\n(EFi)\nSo\nP[E] = P[∪n\ni=1(EFi)]\n=\nn\nX\ni=1\nP[EFi]\n=\nn\nX\ni=1\nP[E|Fi]P[Fi]\n[Law of total probability]\nExample 6.2: You roll a 4-sided die. If result is ≤2, you r"}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 2, "text": ".\n\nBaye’s Theorem and Inference:\nLet F1, F2, . . . , Fn partition S.\nSay we know P[E|Fj] and P[Fj]. We want to compute P[Fj|E]:\nP[Fj|E] = P[EFj]\nP[E]\n=\nP[E|Fj]P[Fj]\nP[E|F1]P[F1] + P[E|F2]P[F2] + · · ·"}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 3, "text": " probabilities are key to practical inference (e.g., classification, pat-\ntern recognition, detection, etc.)\nExample 6.3: A 3-card deck has\n\n• one card with red on both sides\n• one card with black on "}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 4, "text": "\nP[R|{rr}]P[{rr}] + P[R|{rb}]P[{rb}] + P[R|{bb}]P[{bb}]\n=\n1\n2\n1\n3\n1 × 1\n3 + 1\n2\n1\n3 + 0 × 1\n3\n= 1/3\nWhy?\nIf you see red, there are 3 different ways this could happen (one side of rb +\ntwo sides of rr)"}, {"path": ".data\\docs\\ECE 203\\06_cond_prob2.pdf", "chunk_id": 5, "text": "e is present?\nSolution: E = {positive result},\nF = {desease present}\nWhat informaton do we already have?\n\n• P[F] = 0.005, P[F c] = 0.995\n• P[E|F] = 0.95, P[Ec|F] = 0.05\n• P[E|F c] = 0.01, P[Ec|F c] = "}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 0, "text": "7. Conditional Probability and Independence\nIndependent Events [Ross S3.4]\nDefinition 7.1: Events E and F are called independent if\nP[EF] = P[E]P[F]\nTwo events that are not independent are called depe"}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 1, "text": " 3)] = 1/36,\nP[E2]P[F] = 1/6 × 1/6 = 1/36\nSo E1 and F are not independent, but E2 and F are independent.\n\nSimilarly, E2 and G are independent.\nExample 7.2: Say EF = ∅with P[E] > 0 and P[F] > 0. Are E "}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 2, "text": "t of F and E is independent of G, is E\nindependent of FG?\nSolution: Not necessarily. In Example 7.1:\nE2 is independent of F and E2 is independent of G\nNow P[E2] = 6/36,\nbut P[E2|FG] = P[{sum is 7}|(4,"}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 3, "text": "ity of E.\nDefinition 7.3: The 3 events E, F and G are said to be independent if\nP[EFG] = P[E]P[F]P[G]\nP[EF] = P[E]P[F]\nP[EG] = P[E]P[G]\nP[FG] = P[F]P[G]\nNow, E is independent of any event formed from "}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 4, "text": "inite set of events E1, E2, . . . is independent if every\nfinite subset is independent.\nExample 7.6: A system has n components. Each component functions/fails\nindependently of any other. Component i h"}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 5, "text": "· · (1 −pn)\n\nSometimes each Ei is the outcome of one instance of a sequence of repeated\nsub-experiments, e.g., Ei = {i-th coin toss is heads}.\nThese sub-experiments are often called trials (or repeate"}, {"path": ".data\\docs\\ECE 203\\07_cond_prob3.pdf", "chunk_id": 6, "text": "e mutually exclusive and F = E1 ∪E2 ∪· · · .\nNow:\nP[roll a 5] = 4/36 = 1/9\nP[roll a 7] = 6/36\nP[not roll a 5 or 7] = 1 −10/36 = 13/18\n\nand\nP[En] = P[{no 5 or 7 on 1st roll}\n∩· · ·\n∩{no 5 or 7 on n −1 "}, {"path": ".data\\docs\\ECE 203\\08_rand_vars1.pdf", "chunk_id": 0, "text": "8. Random Variables (rv)\nRandom Variables [Ross S4.1]\nAfter an experiment is done, we are often interested in a function of the out-\ncome:\n• e.g., sum of two dice rolls\n• e.g., number of heads after f"}, {"path": ".data\\docs\\ECE 203\\08_rand_vars1.pdf", "chunk_id": 1, "text": "ple 8.2: Toss 3 coins. Let X = # of heads. Then X is a rv that can\nonly take values 0, 1, 2 or 3.\n{X = 0} = {ttt}\n{X = 1} = {tth, tht, htt}\n{X = 2} = {hht, hth, thh}\n{X = 3} = {hhh}\n\nand\nP[{X = 0}] = "}, {"path": ".data\\docs\\ECE 203\\08_rand_vars1.pdf", "chunk_id": 2, "text": "P[Y = 1] = P[EF c ∪EcF] = P[EF c] + P[EcF] = 0.1 × 0.8 + 0.9 × 0.2\nP[Y = 2] = P[EF] = P[E]P[F] = 0.1 × 0.2\nExample 8.4: A flipped coin has probability p of being heads. We flip the\ncoin until a head o"}, {"path": ".data\\docs\\ECE 203\\09_rand_vars2.pdf", "chunk_id": 0, "text": "9. Random Variables (rv)\nDiscrete Random Variables [Ross S4.2]\nDefinition 9.1: A random variable that can take at most a countable number\nof possible outcomes is called a discrete random variable.\nDef"}, {"path": ".data\\docs\\ECE 203\\09_rand_vars2.pdf", "chunk_id": 1, "text": "λk\nk! ,\nfor k = 0, 1, 2, . . .\nand λ > 0 is given.\na) Find C in terms of λ\nb) Find P[X = 0]\n\nc) Find P[X > 1].\nSolution:\na) Since\n∞\nX\nk=0\npX(k) = 1\n⇒\nC×\n∞\nX\nk=0\nλk\nk!\n|\n{z\n}\npower series for eλ\n= 1\n⇒\n"}, {"path": ".data\\docs\\ECE 203\\09_rand_vars2.pdf", "chunk_id": 2, "text": "8\nPlot the CDF FX(x).\nSolution:\nFX(−10) = P[X ≤−10] = 0\nFX(0.999) = P[X ≤0.999] = 0\nFX(1) = P[X ≤1] = 1/4\nFX(1.999) = P[X ≤1.999] = 1/4\nFX(2) = P[X ≤2] = 1/4 + 1/2\nFX(2.999) = P[X ≤2.999] = 3/4\nFX(3) "}, {"path": ".data\\docs\\ECE 203\\09_rand_vars2.pdf", "chunk_id": 3, "text": "ility that\nX assumes that outcome.\nExample 9.3: Say pX(0) = 1/2,\npX(1) = 1/2.\nThen\nE[X] = 0 × 1/2 + 1 × 1/2\n= 1/2\nExample 9.4: Say pX(0) = 1/3,\npX(1) = 2/3.\nThen\nE[X] = 0 × 1/3 + 1 × 2/3\n= 2/3\nExample"}, {"path": ".data\\docs\\ECE 203\\09_rand_vars2.pdf", "chunk_id": 4, "text": "f the 120 students is chosen randomly.\nLet X = # students on bus of randomly chosen student.\nWhat is E[X]?\nSolution: X = {36, 40, 44}.\nP[X = 36] = 36/120\nP[X = 40] = 40/120\nP[X = 44] = 44/120\nSo\nE[X] "}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 0, "text": "10. Random Variables (rv)\nFunctions of a Random Variable [Ross S4.4]\nSay we have a random variable X. Let Y = g(X) for some function g(.).\nThen:\n• X is a function of the outcome s ∈S\n• Y is a function"}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 1, "text": " 1]\n= P[{X = 1} ∪{X = −1}]\n= 0.1 + 0.6\nSo\nE[X2] = E[Y ] = 0 × 0.3 + 1 × 0.7\n= 0.7\nNote: (E[X])2 = (0.5)2 ̸= 0.7 = E[X2].\nSo E[g(X)] ̸= g(E[X]) in general.\nProposition 10.1 If X is a rv with possible v"}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 2, "text": "i\nx2\ni pX(xi)\n= (−1)2 × pX(−1) + 02 × pX(0) + 12 × pX(1)\n= 1 × 0.1 + 0 × 0.3 + 1 × 0.6\n= 0.7\nCorollary 10.1 If a and b are constants, then E[aX + b] = aE[X] + b.\nWhy?\nE[aX + b] =\nX\nx∈X\n(ax + b)pX(x)\n="}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 3, "text": " Let\nP[W = 0] = 1\nP[Y = 1] = P[Y = −1] = 1\n2\nP[Z = 100] = P[Z = −100] = 1\n2\nThen E[W] = 0 = E[Y ] = E[Z], but these are not equally spread...\nDefinition 10.1: The variance of X is\nV ar[X] = E[ (X −E[X"}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 4, "text": "])2\n(10.2)\nand, if E[X] > 0, then\nE[X2]\nE[X] ≥E[X]\n(10.3)\nExample 10.5: Let X be the the outcome of a dice roll. What is V ar[X]?\nSolution:\nE[X] = 1 × 1\n6 + 2 × 1\n6 + · · · + 6 × 1\n6 = 7\n2\nE[X2] = 1 ×"}, {"path": ".data\\docs\\ECE 203\\10_rand_vars3.pdf", "chunk_id": 5, "text": "ood (probability 0.3), the speed is V = 600 km/h.\nWhat is the average flight time?\nSolution: If the wind is good, the flight time T = 4200/700 = 6 hours.\nIf the wind is not good, then T = 4200/600 = 7"}, {"path": ".data\\docs\\ECE 203\\11_rand_vars4.pdf", "chunk_id": 0, "text": "11. Random Variables (rv)\nExamples [Ross S4.5]\nExample 11.1: [Cover if time] [Friendship Paradox]\nThere are n people named 1, 2, . . . , n.\nPerson i has f(i) friends. Let m = Pn\ni=1 f(i).\nLet X be a r"}, {"path": ".data\\docs\\ECE 203\\11_rand_vars4.pdf", "chunk_id": 1, "text": "heet is drawn at random, each sheet being\nequally likely to be chosen.\nLet\nY = name of friend on drawn sheet\nW = f(Y )\n\nNow\nP[Y = i] = f(i)\nm\n\u0014\nas opposed to 1\nn\n\u0015\nE[W] = E[f(Y )]\n=\nX\ni\nf(i) P[Y = i]\n"}, {"path": ".data\\docs\\ECE 203\\11_rand_vars4.pdf", "chunk_id": 2, "text": "n same day}\na) Find P[A1,3]\nb) Find P[A1,3 | A1,2]\n\nSolution:\na)\nP[A1,3] = P[∪r{1 and 3 both born on day r}]\n=\nX\nr\nP[{1 and 3 both born on day r}]\n=\nX\nr\nP[{1 born on day r}]P[{3 born on day r}]\n=\nX\nr\n"}, {"path": ".data\\docs\\ECE 203\\11_rand_vars4.pdf", "chunk_id": 3, "text": "(X −E[X])2i\n= a2 V ar[X]\nRemark 11.2: If X has units of, say, kg, then:\n• E[X] = µX has units of kg,\n• V ar[X] = σ2\nX has units of kg2.\nWe also define SD[X] =\np\nV ar[X] = σX, called standard deviation"}, {"path": ".data\\docs\\ECE 203\\12_rand_vars5.pdf", "chunk_id": 0, "text": "12. Random Variables (rv)\nBernoulli and Binomial [Ross S4.6]\nA) Let\npX(k) =\n(\n1 −p\nif k = 0\np\nif k = 1\nwith 0 ≤p ≤1.\nThen X is called Bernoulli with parameter p, denoted X ∼Bernoulli(p).\nThis random v"}, {"path": ".data\\docs\\ECE 203\\12_rand_vars5.pdf", "chunk_id": 1, "text": "es from n Bernoulli trials.\n\nEach has probability pk(1 −p)n−k. So\npX(k) =\n(\u0000n\nk\n\u0001\npk(1 −p)n−k\n0 ≤k ≤n\n0\nelse\nNote: Since X must be between 0 and n:\n1 =\nn\nX\nk=0\npX(k) =\nn\nX\nk=0\n\u0012n\nk\n\u0013\npk(1 −p)n−k\nExamp"}, {"path": ".data\\docs\\ECE 203\\12_rand_vars5.pdf", "chunk_id": 2, "text": "replaced] = 1 −P[not replaced]\n≈0.004\nMoments of Binomial\n\nLet X ∼Binomial(n, p). Then\nE[X]\n= np\nE[X2]\n= n(n −1)p2 + np\n\u0015\nWill prove these later\nSo\nV ar[X] = E[X2] −(E[X])2\n= n(n −1)p2 + np −(np)2\n= n"}, {"path": ".data\\docs\\ECE 203\\12_rand_vars5.pdf", "chunk_id": 3, "text": " small enough)\ni.e.: Poisson(λ) is Binomial(n, λ/n) when n →∞.\nWhy? Let X ∼Binomial(n, p) with p = λ/n:\n\npX(k) =\nn!\n(n −k)! k! pk(1 −p)n−k\n=\nn!\n(n −k)! k!\n\u0012λ\nn\n\u0013k \u0012\n1 −λ\nn\n\u0013n−k\n= n(n −1) · · · (n −k +"}, {"path": ".data\\docs\\ECE 203\\12_rand_vars5.pdf", "chunk_id": 4, "text": "\nPoisson should be a good approximation for:\n• # of typos on a page\n• # of oranges sold at a store in one day\n• # of alpha particles emitted by a radioactive substance in 1 second\n• # of dead pixels i"}, {"path": ".data\\docs\\ECE 203\\13_rand_vars6.pdf", "chunk_id": 0, "text": "13. Random Variables (rv)\nMean and Variance of Poisson [Ross S4.7]\nIntuition: Say X ∼Binomial(n, p)\nwith λ = np, n large, so p small\nThen:\nE[X] = np = λ\nV ar[X] = np(1 −p)\n= λ(1 −p)\n≈λ\nExact: Let X ∼P"}, {"path": ".data\\docs\\ECE 203\\13_rand_vars6.pdf", "chunk_id": 1, "text": "\nSo\nV ar[X] = E[X2] −(E[X])2\n= λ(1 + λ) −(λ)2\n= λ\nExample 13.1: A radioactive substance with a large # of atoms emits 3.2\nalpha particles per second on average. What is the probability that no more\nth"}, {"path": ".data\\docs\\ECE 203\\13_rand_vars6.pdf", "chunk_id": 2, "text": "l # of first outcome that is a 1.\nX is called geometric with parameter p, denoted X ∼Geometric(p)\npX(k) = P[(k −1) zeros followed by a one]\nfor k = 1, 2, . . .\n=\n(\n(1 −p)k−1p\nk ≥1\n0\nelse\nExample 13.2:"}, {"path": ".data\\docs\\ECE 203\\13_rand_vars6.pdf", "chunk_id": 3, "text": " # of draws until a black ball, then X ∼Geometric(p) with p = 0.6.\na)\nP[X = n] =\n\u0012\n1 −3\n5\n\u0013n−1\n× 3\n5\n=\n\u00122\n5\n\u0013n−1\n× 3\n5\n\nb)\nP[X ≥k] =\n∞\nX\nn=k\nP[X = n]\n= 3\n5 ×\n∞\nX\nn=k\n\u00122\n5\n\u0013n−1\n= 3\n5 ×\n\u00122\n5\n\u0013k−1\n∞\nX\nn="}, {"path": ".data\\docs\\ECE 203\\14_rand_vars7.pdf", "chunk_id": 0, "text": "14. Random Variables (rvs)\nExpectation of sums of random variables [Ross S4.9]\nRecall, a random variable X is a function X(s) of the outcome s of a random\nexperiment.\nWe can have two functions of the "}, {"path": ".data\\docs\\ECE 203\\14_rand_vars7.pdf", "chunk_id": 1, "text": " . . , xn}\nAk = {s ∈S | X(s) = xk}\n\nThen\nE[X] =\nn\nX\nk=1\nxkP[X = xk]\n=\nn\nX\nk=1\nxkP[Ak]\n=\nn\nX\nk=1\nxk\nX\ns∈Ak\np(s)\n=\nn\nX\nk=1\nX\ns∈Ak\nxkp(s)\n=\nn\nX\nk=1\nX\ns∈Ak\nX(s)p(s)\n=\nX\ns∈S\nX(s)p(s)\nExample 14.2: Two inde"}, {"path": ".data\\docs\\ECE 203\\14_rand_vars7.pdf", "chunk_id": 2, "text": "et Z(s) = X(s) + Y (s). What is E[Z]?\nE[Z] =\nX\ns∈S\nZ(s)p(s)\n=\nX\ns∈S\n( X(s) + Y (s) )p(s)\n=\nX\ns∈S\nX(s)p(s) +\nX\ns∈S\nY (s)p(s)\n= E[X] + E[Y ]\nThis result can be generalized.\nProposition 14.1 For random v"}, {"path": ".data\\docs\\ECE 203\\14_rand_vars7.pdf", "chunk_id": 3, "text": "umber of 1’s in the n trials. So X ∼Binomial(n, p).\nAlso:\nE[X] = E[X1 + · · · + Xn]\n= E[X1] + · · · + E[Xn]\n[by Proposition 14.1]\n= p + · · · + p\n= np\nE[X2] = E\n\" n\nX\nk=1\nXk\n!  n\nX\nℓ=1\nXℓ\n!#\n= E\n\" n\nX"}, {"path": ".data\\docs\\ECE 203\\14_rand_vars7.pdf", "chunk_id": 4, "text": "2) If a < b then {X ≤a} ⊂{X ≤b}\n⇒P[X ≤a] ≤P[X ≤b]\n⇒FX(a) ≤FX(b)\nor, FX(x) is non-decreasing in x.\nIt can also be show that:\n3)\nlim\nx→∞FX(x) = 1\n\n4)\nlim\nx→−∞FX(x) = 0\n5) lim\nx↓b FX(x) = FX(b)\n[i.e., FX"}, {"path": ".data\\docs\\ECE 203\\15_cont_rand_vars1.pdf", "chunk_id": 0, "text": "15. Continuous Random Variables\n[Ross S5.1]\nWe saw random variables where the set of possible outcomes was discrete. In\nsome cases, a random variable can take a continuum of values:\nX = time at which "}, {"path": ".data\\docs\\ECE 203\\15_cont_rand_vars1.pdf", "chunk_id": 1, "text": "ρ(x), the density of mass in kg/m3\nat every point x ∈R3, then the mass inside any volume V is:\n\nm(V ) =\n˚\nV\nρ(x) dx\nfX(x) is similar, except it measures the density of probability, not mass:\nP[X ∈B] ="}, {"path": ".data\\docs\\ECE 203\\15_cont_rand_vars1.pdf", "chunk_id": 2, "text": " =\n´ a\n−∞fX(x)dx\n4) fX(a) =\nd\ndaFX(a)\nExample 15.1: The lifetime of a motor in months is a random variable with\npdf\nfX(x) =\n(\nλe−x/100\nx ≥0\n0\nx < 0\nfor some unknown constant λ. What is the probability"}, {"path": ".data\\docs\\ECE 203\\15_cont_rand_vars1.pdf", "chunk_id": 3, "text": "1 −e−1\n≈0.632\n\nExample 15.2: Let X have pdf fX(x), and Y = 2X. Find fY (y).\nSolution:\nFY (a) = P[Y ≤a]\n= P[2X ≤a]\n= P[X ≤a\n2]\n= FX\n\u0010a\n2\n\u0011\nand\nfY (a) = d\ndaFX\n\u0010a\n2\n\u0011\n= fX\n\u0010a\n2\n\u0011\n× 1\n2\nNote:\nˆ ∞\n−∞\nfY ("}, {"path": ".data\\docs\\ECE 203\\16_cont_rand_vars2.pdf", "chunk_id": 0, "text": "16. Continuous Random Variables\nExpectation [Ross 5.2]\nDefinition 16.1: For a continuous random variable X,\nE[X] =\nZ ∞\n−∞\nxfX(x)dx.\nExample 16.1: Find E[X] if\nfX(x) =\n(\n2x\n0 ≤x ≤1\n0\nelse\nSolution:\nE[X"}, {"path": ".data\\docs\\ECE 203\\16_cont_rand_vars2.pdf", "chunk_id": 1, "text": "cannot take values outside this interval, so outside this interval fY (y) = 0.\nFinally\nE[Y ] =\nZ ∞\n−∞\nyfY (y)dy\n=\nZ e\n1\ny × 1\ny dy\n= e −1\nProposition 16.1 For a continuous random variable X,\nE[g(X)] ="}, {"path": ".data\\docs\\ECE 203\\16_cont_rand_vars2.pdf", "chunk_id": 2, "text": "u\n= E[X]\nExample 16.4: A point p on a stick of length 1, where 0 ≤p ≤1 is fixed.\n\nLet the stick be broken at U, where\nfU(u) =\n(\n1\n0 ≤u ≤1\n0\nelse\nDetermine the expected length of the piece that contain"}, {"path": ".data\\docs\\ECE 203\\16_cont_rand_vars2.pdf", "chunk_id": 3, "text": "\nZ ∞\n−∞\nfX(x)dx\n= aE[X] + b\nDefinition 16.2: For a continuous random variable X,\nV ar[X] = E[(X −E[X])2]\nAgain, V ar[X] = E[X2] −(E[X])2\nAlso, V ar[aX + b] = a2V ar[X].\nExample 16.5: Find V ar[X] in E"}, {"path": ".data\\docs\\ECE 203\\17_cont_rand_vars3.pdf", "chunk_id": 0, "text": "17. Continuous Random Variables\nCommon continuous random variables\nA) Uniform random variables [Ross 5.3]\nWe say X is uniform on the interval (a, b), denoted X ∼U(a, b), if\nfX(x) =\n(\n1\nb−a\na < x < b\n0"}, {"path": ".data\\docs\\ECE 203\\17_cont_rand_vars3.pdf", "chunk_id": 1, "text": "t 7:00 that person arrives. Then X ∼\nU(0, 30).\nP[wait less than 5 min] = P[{10 < X < 15} ∪{25 < X < 30}]\n=\nZ 15\n10\n1\n30dx +\nZ 30\n25\n1\n30dx\n= 1/3\n\nExample 17.2: Let X ∼U(a, b). Find E[X] and V ar[X].\nS"}, {"path": ".data\\docs\\ECE 203\\17_cont_rand_vars3.pdf", "chunk_id": 2, "text": "ussian) with parameters µ and σ2 if\nfX(x) =\n1\n√\n2πσ e−(x−µ)2\n2σ2\n(17.1)\nThis is denoted X ∼N(µ, σ2).\n\nTo verify that fX(x) has unit area, see Notes #21.\nNote: If X has units of kg, then µ has units of"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 0, "text": "18. Continuous Random Variables\n2) Normal (Gaussian) random variables [Ross 5.4]\nExample 18.1: Let X ∼N(µ, σ2). Find the distribution of Z = (X −µ)/σ.\nSolution:\nZ = X −µ\nσ\n= 1\nσ X −µ\nσ\nPlugging a = 1/"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 1, "text": "(z)dz\n=\n1\n√\n2π\nZ ∞\n−∞\nze−z2/2dz\n= −1\n√\n2π e−z2/2\f\f\f\n∞\n−∞\n= 0\nV ar[Z] = E[Z2] −(E[Z])2\n= E[Z2]\n=\n1\n√\n2π\nZ ∞\n−∞\nz2e−z2/2dz\nd(uv) = du v + u dv\n=\n1\n√\n2π\nZ ∞\n−∞\nz\n|{z}\nu\n· ze−z2/2dz\n|\n{z\n}\ndv\nuv =\nZ\nvdu +"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 2, "text": "]\nQ(z) =\n1\n√\n2π\nZ ∞\nz\ne−u2/2du\n[Q-function]\nzα = value such that: P[Z > zα] = α\nfor 0 ≤α ≤1\n= Q−1(α) = Φ−1(1 −α)\nNote: Φ(z) + Q(z) = 1; Φ(−z) = Q(z) = 1 −Φ(z).\nThere is also the “error function”:\nerf("}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 3, "text": "0.53983\n0.54380\n0.54776\n0.55172\n0.55567\n0.55962\n0.56356\n0.56749\n0.57142\n0.57535\n0.2\n0.57926\n0.58317\n0.58706\n0.59095\n0.59483\n0.59871\n0.60257\n0.60642\n0.61026\n0.61409\n0.3\n0.61791\n0.62172\n0.62552\n0.62930\n"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 4, "text": "0.77935\n0.78230\n0.78524\n0.8\n0.78814\n0.79103\n0.79389\n0.79673\n0.79955\n0.80234\n0.80511\n0.80785\n0.81057\n0.81327\n0.9\n0.81594\n0.81859\n0.82121\n0.82381\n0.82639\n0.82894\n0.83147\n0.83398\n0.83646\n0.83891\n1.0\n0.84"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 5, "text": "364\n0.92507\n0.92647\n0.92785\n0.92922\n0.93056\n0.93189\n1.5\n0.93319\n0.93448\n0.93574\n0.93699\n0.93822\n0.93943\n0.94062\n0.94179\n0.94295\n0.94408\n1.6\n0.94520\n0.94630\n0.94738\n0.94845\n0.94950\n0.95053\n0.95154\n0.95"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 6, "text": "0.98214\n0.98257\n0.98300\n0.98341\n0.98382\n0.98422\n0.98461\n0.98500\n0.98537\n0.98574\n2.2\n0.98610\n0.98645\n0.98679\n0.98713\n0.98745\n0.98778\n0.98809\n0.98840\n0.98870\n0.98899\n2.3\n0.98928\n0.98956\n0.98983\n0.99010\n"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 7, "text": "0.99720\n0.99728\n0.99736\n2.8\n0.99744\n0.99752\n0.99760\n0.99767\n0.99774\n0.99781\n0.99788\n0.99795\n0.99801\n0.99807\n2.9\n0.99813\n0.99819\n0.99825\n0.99831\n0.99836\n0.99841\n0.99846\n0.99851\n0.99856\n0.99861\n3.0\n0.99"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 8, "text": "970\n0.99971\n0.99972\n0.99973\n0.99974\n0.99975\n0.99976\nFor Gaussian other than N(0, 1), Φ(.) can still be used with proper transfor-\nmation:\nExample 18.3: Let X ∼N(3, 9). Compute P[2 < X < 5].\n\nSolution:"}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 9, "text": "In finance, the Value At Risk (VaR) of an investment is the\nvalue v > 0 such that there is only a 1% chance the investment will lose more\nthan v.\nIf the profit from an investment is X ∼N(µ, σ2), what "}, {"path": ".data\\docs\\ECE 203\\18_cont_rand_vars4.pdf", "chunk_id": 10, "text": "rmal distribution is used (and mis-used) a lot:\n• Central Limit Thm: normal is a good approximation when observation\nis sum of many small independent components, e.g., thermal noise\n• A good model for"}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 0, "text": "19. Continuous Random Variables\nC) Exponential Random Variable [Ross S5.5]\nA random variable X with pdf\nfX(x) =\n(\nλe−λx\nx ≥0\n0\nelse\nis called exponential with rate parameter λ > 0 and denoted X ∼Exp(λ"}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 1, "text": "xn−1dx\n\u0015\n= n\nλ\nZ ∞\n0\nxn−1λe−λxdx\n\n= n\nλE[Xn−1]\nSince E[X0] = E[1] = 1, then\nE[X] = 1\nλE[X0] = 1\nλ\nE[X2] = 2\nλE[X1] = 2\nλ2\nHence\nV ar[X] = E[X2] −(E[X])2\n= 2\nλ2 −\n\u0012 1\nλ\n\u00132\n= 1\nλ2\nExample 19.2: The time"}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 2, "text": "p(−2) ≈0.23254\n\nDefinition 19.1: A non-negative random variable X is called memoryless if\nfor all s > 0 and all t > 0\nP[X > s + t | X > t] = P[X > s]\nIn words: The probability of waiting s seconds mor"}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 3, "text": ")\ne−λt\n= e−λs\n= P[X > s]\nYes, Exp(λ) has the memoryless property.\nExample 19.4: Persons A and B are each being served by a teller. Person C\narrives, and waits for one of the two tellers. All service t"}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 4, "text": " 19.5: [Cover if time] A car battery has a lifetime that is exponen-\ntially distributed with mean 10, 000 km.\na) What is the probability of completing a 5000 km trip without replacing the\nbattery?\nb) "}, {"path": ".data\\docs\\ECE 203\\19_cont_rand_vars5.pdf", "chunk_id": 5, "text": "P[X > d + 5000]\nP[X > d]\n= 1 −FX(d + 5000)\n1 −FX(d)\n.\nThe exponential distribution is often used to measure durations due to mem-\noryless property:\n\n• service times in queuing systems,\n• time between "}, {"path": ".data\\docs\\ECE 203\\20_cont_rand_vars6.pdf", "chunk_id": 0, "text": "20. Continuous Random Variables\nDistribution of a function of a random variable [Ross S5.7]\nGiven a random variable X and Y = g(X), want to find pdf of Y .\nTwo-step approach: i) calculate\nFY (y) = P[g"}, {"path": ".data\\docs\\ECE 203\\20_cont_rand_vars6.pdf", "chunk_id": 1, "text": " =\n\n\n\n\n\n\n\n0\ny < 0\ny2\n0 ≤y ≤1\n1\n1 < y\n(20.3)\nii) Differentiating, we get\nfY (y) = d\ndy FY (y)\n=\n\n\n\n\n\n\n\n0\ny < 0\n2y\n0 ≤y ≤1\n0\n1 < y\nExample 20.2: Let Y = X2. What is fY (y) in terms of fX(x"}, {"path": ".data\\docs\\ECE 203\\20_cont_rand_vars6.pdf", "chunk_id": 2, "text": "y]\n= P[aX + b ≤y]\n= P\n\u0014\nX ≤y −b\na\n\u0015\n= FX\n\u0012y −b\na\n\u0013\nfY (y) = d\ndy FY (y)\n= d\ndy FX\n\u0012y −b\na\n\u0013\n= 1\nafX\n\u0012y −b\na\n\u0013\n\nIf a < 0:\nFY (y) = P[Y ≤y]\n= P[aX + b ≤y]\n= P\n\u0014\nX ≥y −b\na\n\u0015\n[We divided by a < 0]\n= 1 −P\n"}, {"path": ".data\\docs\\ECE 203\\20_cont_rand_vars6.pdf", "chunk_id": 3, "text": "e differentiable and either strictly increasing or strictly decreasing.\n\nThen Y = g(X) has pdf\nfY (y) =\n\n\n\nfX\n\u0000g−1(y)\n\u0001 \f\f\f d\ndyg−1(y)\n\f\f\f\nif y = g(x) for some x\n0\nelse\nWhy? Only consider the case "}, {"path": ".data\\docs\\ECE 203\\21_cont_rand_vars7.pdf", "chunk_id": 0, "text": "21. Continuous Random Variables\nAppendix [Ross S5.4]\nThe result below shows that a Gaussian pdf has unit area under its curve.\nProposition 21.1\n1\n√\n2πσ\nZ ∞\n−∞\ne−(x−µ)2\n2σ2 dx = 1\nWhy?\nLet u = (x −µ)/σ"}, {"path": ".data\\docs\\ECE 203\\22_joint_dist_rv1.pdf", "chunk_id": 0, "text": "22. Jointly Distributed Random Variables\nTwo random variables [Ross S6.1]\nSo far, we only considered the distribution of a single random variable.\nSay we want the probability of an event involving 2 r"}, {"path": ".data\\docs\\ECE 203\\22_joint_dist_rv1.pdf", "chunk_id": 1, "text": " X takes values in X = {x1, x2, . . .},\n• Y takes values in Y = {y1, y2, . . .}.\nWe define the joint probability mass function (joint pmf):\npXY (x, y) = P[X = x, Y = y]\n\nThen\npX(x) = P[X = x]\n= P[∪j{X"}, {"path": ".data\\docs\\ECE 203\\22_joint_dist_rv1.pdf", "chunk_id": 2, "text": "\nAlso\n1 = P[X ∈X, Y ∈Y]\n= P[∪i,j{X = xi, Y = yj}]\n=\nX\ni,j\nP[X = xi, Y = yj]\n=\nX\ni,j\npXY (xi, yj)\nSo joint pmf must sum to 1.\nExample 22.1: An urn contains 3 red, 4 white and 5 blue balls. 3 balls are\n"}, {"path": ".data\\docs\\ECE 203\\22_joint_dist_rv1.pdf", "chunk_id": 3, "text": "om 5 blue\n⇒\npXY (i, j) =\n\u00003\ni\n\u0001\u00004\nj\n\u0001\u00005\n3−i−j\n\u0001\n\u000012\n3\n\u0001\nContinuous Case:\nX and Y are jointly continuous random variables if there exists a non-negative\nfXY (x, y) such that for every C ⊂R2:\nP[(X, Y ) "}, {"path": ".data\\docs\\ECE 203\\22_joint_dist_rv1.pdf", "chunk_id": 4, "text": "to a and b in (22.1)\nfXY (a, b) =\n∂2\n∂a∂b FXY (a, b)\nAlso\nZ\nA\nfX(x)dx = P[X ∈A]\n= P[X ∈A, Y ∈(−∞, ∞)]\n=\nZ\nA\nZ ∞\n−∞\nfXY (x, y) dydx\nSo\nfX(x) =\nZ ∞\n−∞\nfXY (x, y)dy\n[marginalization]\nLikewise\nfY (y) =\nZ "}, {"path": ".data\\docs\\ECE 203\\23_joint_dist_rv2.pdf", "chunk_id": 0, "text": "23. Jointly Distributed Random Variables\nExamples [Ross S6.1]\nExample 23.1: The joint pdf of X and Y is given by\nfXY (x, y) =\n(\n2e−xe−2y\nx > 0 and y > 0\n0\nelse\nCompute\na) P[X > 1, Y < 1]\nb) P[X < Y ]\n"}, {"path": ".data\\docs\\ECE 203\\23_joint_dist_rv2.pdf", "chunk_id": 1, "text": "\n=\nZ ∞\n0\n2e−2y −2e−3ydy\n=\n\u0014\n−e−2y + 2\n3e−3y\n\u0015∞\n0\n= 1 −2\n3\n= 1\n3\nc)\nP[X < a] = P[X ∈(−∞, a), Y ∈(−∞, ∞)]\n\n=\nZ ∞\n−∞\nZ a\n−∞\nfXY (x, y)dxdy\n=\nZ ∞\n0\nZ a\n0\n2e−xe−2ydxdy\n=\nZ ∞\n0\n\u0002\n−2e−xe−2y\u0003x=a\nx=0 dy\n=\nZ ∞\n"}, {"path": ".data\\docs\\ECE 203\\23_joint_dist_rv2.pdf", "chunk_id": 2, "text": "us R.\nSolution:\n\na)\n1 =\nZZ\nR2\nfXY (x, y)dxdy\n=\nZZ\nx2+y2≤R2\nc dxdy\n= c\nZZ\nx2+y2≤R2\n1 dxdy\n= c × πR2\nSo, c = 1/πR2.\nb)\nfX(x) =\nZ ∞\n−∞\nfXY (x, y)dy\n=\nZ\ny:x2+y2≤R2 c dy\n=\nZ\ny:y2≤R2−x2 c dy\n(23.1)\n=\nZ √\nR2"}, {"path": ".data\\docs\\ECE 203\\23_joint_dist_rv2.pdf", "chunk_id": 3, "text": "\nFormally:\nP[D ≤a] = P[X2 + Y 2 ≤a2]\n=\nZZ\nx2+y2≤a2\nfXY (x, y) dxdy\n=\nZZ\nx2+y2≤R2\nc dxdy +\nZZ\nR2<x2+y2≤a2\n0 dxdy\n= c × πR2\n= 1\nIf a < 0, since D can’t be negative, P[D ≤a] = 0.\nd) The pdf of D for 0 ≤a"}, {"path": ".data\\docs\\ECE 203\\23_joint_dist_rv2.pdf", "chunk_id": 4, "text": "≤ay\nfXY (x, y)dxdy\n=\nZ ∞\n0\nZ ay\n0\ne−xe−y dxdy\n=\nZ ∞\n0\n(1 −e−ay)e−y dy\n=\nZ ∞\n0\ne−y −e−(1+a)y dy\n= 1 −\n1\n1 + a\n\nand FZ(a) = 0 for a ≤0.\nTherefore\nfZ(a) = d\ndaFZ(a)\n=\n(\n1\n(1+a)2\na > 0\n0\nelse"}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 0, "text": "24. Jointly Distributed Random Variables\nMultiple Joint Random Variables [Ross S6.1]\nThe joint CDF of random variables X1, X2, . . . , Xn is\nFX1,X2,...,Xn(a1, a2, ..., an) = P[X1 ≤a1, X2 ≤a2, . . . , "}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 1, "text": " . . , Xn are continuous rv’s if there is a non-negative fX1,...,Xn(x1, . . . , xn)\nsuch that for all C ⊂Rn:\nP[(X1, . . . , Xn) ∈C] =\nZ\n· · ·\nZ\nC\nfX1,...,Xn(x1, . . . , xn) dx1 · · · dxn\n\nSo,\nP[X1 ∈A1"}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 2, "text": "=\nZ ∞\n−∞\nfX1,X2,...,Xn(x1, x2, . . . , xn) dx1\n[marginalization]\n2)\n1 = P[X1 ∈(−∞, ∞), . . . , Xn ∈(−∞, ∞)]\n=\nZ ∞\n−∞\n· · ·\nZ ∞\n−∞\nfX1,...,Xn(x1, . . . , xn) dx1 · · · dxn\nExample 24.1: Let X, Y and Z "}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 3, "text": "e Z:\nfXY (x, y) =\nZ ∞\n−∞\nfXY Z(x, y, z) dz\n=\nZ\nz:x2+y2+z2≤R2\nc dz\n=\n(\n0\nx2 + y2 > R2\nR a\n−a c dz\nx2 + y2 ≤R2\nwhere a =\np\nR2 −(x2 + y2)\n=\n(\n0\nx2 + y2 > R2\n2ac\nx2 + y2 ≤R2\n=\n(\n0\nx2 + y2 > R2\n3\n2πR3\np\nR2"}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 4, "text": "not change the probabilities of\nthe outcomes of Y .\nSay X and Y are independent. Choosing A = (−∞, x] and B = (−∞, y]:\nFXY (x, y) = P[X ∈A, Y ∈B]\n= P[X ∈A]P[Y ∈B]\nby independence\n= FX(x)FY (y)\n∀a, b ∈"}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 5, "text": "∈B]\n[using (24.1)]\n= pX(x)pY (y)\nii) (24.3) implies (24.1):\nP[X ∈A, Y ∈B] =\nX\nx∈A,y∈B\npXY (x, y)\n=\nX\nx∈A,y∈B\npX(x)pY (y)\n[using (24.3)]\n=\nX\nx∈A\npX(x)\nX\ny∈B\npY (y)\n= P[X ∈A]P[Y ∈B]\nContinuous Case:\nIf "}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 6, "text": "v\n= FX(x)FY (y)\nSummary:\nThe discrete rv’s X and Y are independent is equivalent to all three:\nP[X ∈A, Y ∈B] = P[X ∈A]P[Y ∈B]\n∀A, B ⊂R\n(24.1)\nFXY (x, y) = FX(x)FY (y)\n∀x, y ∈R\n(24.2)\npXY (x, y) = pX(x"}, {"path": ".data\\docs\\ECE 203\\24_joint_dist_rv3.pdf", "chunk_id": 7, "text": "if for any\n\nsets A1, ..., An:\nP[X1 ∈A1, . . . , Xn ∈An] = P[X1 ∈A1] × · · · × P[Xn ∈An]\nAgain, this is equivalent to\nFX1,...,Xn(a1, . . . , an) = FX1(a1) × · · · × FXn(an)\nfor all a1, . . . , an.\nAn i"}, {"path": ".data\\docs\\ECE 203\\25_joint_dist_rv4.pdf", "chunk_id": 0, "text": "25. Jointly Distributed Random Variables\nExample 25.1: Let X and Y have joint density\nfXY (x, y) =\n(\n6e−2xe−3y\nx > 0, y > 0\n0\nelse\nAre X and Y independent?\nSolution: Compute the marginals fX(x) and fY"}, {"path": ".data\\docs\\ECE 203\\25_joint_dist_rv4.pdf", "chunk_id": 1, "text": "\n1 =\nZ ∞\n−∞\nZ ∞\n−∞\nfXY (x, y) dxdy\n=\nZ ∞\n−∞\nZ ∞\n−∞\nh(x)g(y) dxdy\n=\nZ ∞\n−∞\nh(x) dx\n|\n{z\n}\nC1\nZ ∞\n−∞\ng(y) dy\n|\n{z\n}\nC2\n= C1C2\nNow,\nfX(x) =\nZ ∞\n−∞\nfXY (x, y)dy =\nZ ∞\n−∞\nh(x)g(y)dy = C2h(x)\nfY (y) =\nZ ∞\n−"}, {"path": ".data\\docs\\ECE 203\\25_joint_dist_rv4.pdf", "chunk_id": 2, "text": "(x) and g(y).\nExample 25.2: Let X and Y have joint pdf\nfXY (x, y) =\n(\n24xy\nx > 0, y > 0, 0 < x + y < 1\n0\nelse\nAre X and Y independent?\nSolution: No. Below is the region where fXY (x, y) > 0.\nThis regi"}, {"path": ".data\\docs\\ECE 203\\25_joint_dist_rv4.pdf", "chunk_id": 3, "text": " arrive is min(X, Y )\n\nTime of last to arrive is max(X, Y )\nWe want P[{max(X, Y ) > min(X, Y ) + 10}\n|\n{z\n}\nE\n]\nand E = {Y > X + 10} ∪{X > Y + 10}\nP[E] = 2P[Y > X + 10]\n= 2\nZZ\ny>x+10\nfXY (x, y)dxdy\n= "}, {"path": ".data\\docs\\ECE 203\\26_joint_dist_rv5.pdf", "chunk_id": 0, "text": "26. Jointly Distributed Random Variables\nSums of Independent Random Variables [Ross S6.3]\nSay X and Y are independent continuous random variables. What is the pdf\nof Z = X + Y ?\nFZ(z) = P[X + Y ≤z]\n=\n"}, {"path": ".data\\docs\\ECE 203\\26_joint_dist_rv5.pdf", "chunk_id": 1, "text": "U(0, 1) are independent. What is the\npdf of Z = X + Y ?\nSolution:\nCalculating the area of these rectangles:\nfZ(z) =\n\n\n\n\n\n\n\n(z −0) × 1\n0 ≤z ≤1\n(1 −(z −1)) × 1\n1 ≤z ≤2\n0\nelse\n\n=\n\n\n\n\n\n\n\nz\n0"}, {"path": ".data\\docs\\ECE 203\\26_joint_dist_rv5.pdf", "chunk_id": 2, "text": "e follows by repeatedly applying the 2 variables case.\nDefinition 26.1: A random variable Y is called lognormal with parameters\nµ and σ when log Y is ∼N(µ, σ2),\ni.e., when Y = eX where X ∼N(µ, σ2).\nDe"}, {"path": ".data\\docs\\ECE 203\\26_joint_dist_rv5.pdf", "chunk_id": 3, "text": "a) the value increases in each of the next two weeks?\nb) the value at the end of two weeks is higher than it is today?\nSolution: Let U1 ∼N(µ, σ2), U2 ∼N(µ, σ2), Z1 ∼N(0, 1) and\nZ2 ∼N(0, 1) be independ"}, {"path": ".data\\docs\\ECE 203\\26_joint_dist_rv5.pdf", "chunk_id": 4, "text": " −2µ\n√\n2σ2\n> 0 −2µ\n√\n2σ2\n\u0015\n= P\n\u0014\nZ > −2µ\n√\n2σ2\n\u0015\n= 1 −Φ\n\u0012\n−2µ\n√\n2σ2\n\u0013\nExample 26.3: Let X ∼Poisson(λ1) and Y ∼Poisson(λ2) be independent.\nWhat is the pmf of Z = X + Y ?\nSolution:\nIf n < 0: P[X + Y = n"}, {"path": ".data\\docs\\ECE 203\\27_joint_dist_rv6.pdf", "chunk_id": 0, "text": "27. Jointly Distributed Random Variables\nConditional Distributions:\nDiscrete Case [Ross S6.4]\nRecall that for P[F] > 0:\nP[E|F] = P[EF]\nP[F]\nSay pY (y) > 0. The conditional pmf for X given Y is\npX|Y (x"}, {"path": ".data\\docs\\ECE 203\\27_joint_dist_rv6.pdf", "chunk_id": 1, "text": "dependent.\nFind the conditional pmf for X given X + Y = n.\nSolution:\nP[X = k | X + Y = n] = P[X = k, X + Y = n]\nP[X + Y = n]\n= P[X = k, Y = n −k]\nP[X + Y = n]\n= P[X = k]P[Y = n −k]\nP[X + Y = n]\n(27.1)"}, {"path": ".data\\docs\\ECE 203\\27_joint_dist_rv6.pdf", "chunk_id": 2, "text": "and λ1/(λ1 + λ2).\nExample 27.2: [Cover if time] Let X1, X2, . . . , Xn be iid and ∼Bernoulli(p).\nSay these result in k ones. Show that each of the\n\u0000n\nk\n\u0001\npossible orderings of k\nones are then equally "}, {"path": ".data\\docs\\ECE 203\\27_joint_dist_rv6.pdf", "chunk_id": 3, "text": "when x1 + · · · + xn = k.\nContinuous Case [Ross S6.5]\nIf X and Y are continuous, for fY (y) > 0, the conditional pdf of X given\nY = y is\nfX|Y (x|y) = fXY (x, y)\nfY (y)\nWe also define:\nP[X ∈A|Y = y] =\n"}, {"path": ".data\\docs\\ECE 203\\27_joint_dist_rv6.pdf", "chunk_id": 4, "text": ")\n= fX(x)\nExample 27.3: The joint pdf of X and Y is\nfXY (x, y) =\n(\ne−x/ye−y\ny\nx > 0, y > 0\n0\nelse\nFind P[X > 1|Y = 1].\nSolution:\n\nFor y > 0 and x > 0:\nfX|Y (x|y) = fXY (x, y)\nfY (y)\n=\nfXY (x, y)\nR ∞\n−"}, {"path": ".data\\docs\\ECE 203\\28_joint_dist_rv7.pdf", "chunk_id": 0, "text": "28. Jointly Distributed Random Variables\nThe bivariate normal distribution [Ross S6.5]\nTwo random variables X and Y are jointly Gaussian (normal) or bivariate\nGaussian (normal) with parameters:\nµX, µY"}, {"path": ".data\\docs\\ECE 203\\28_joint_dist_rv7.pdf", "chunk_id": 1, "text": "rix of (X, Y ).\nWe say that the pair (X, Y ) ∼N(µ, Σ).\nNote: Σ is symmetric and +ve definite.\n\nMarginal Distributions\nTo find the marginal\nfY (y) =\nZ ∞\n−∞\nfXY (x, y)dx\nand from (28.1) + lots of algebr"}, {"path": ".data\\docs\\ECE 203\\28_joint_dist_rv7.pdf", "chunk_id": 2, "text": "s the pdf of a Gaussian when X has mean\nK3 = µX + ρσX\nσY\n(y −µY )\nand variance K2 = σ2\nX(1 −ρ2).\nNote that we have\nfXY (x, y) = fX(x)fY (y) ⇔fX|Y (x|y) = fX(x)\nand the latter happens when ρ = 0.\nSo fo"}, {"path": ".data\\docs\\ECE 203\\29_joint_dist_rv8.pdf", "chunk_id": 0, "text": "29. Jointly Distributed Random Variables\nJoint Distribution of Functions of Random Variables [Ross S6.7]\nLet X and Y have joint pdf fXY (x, y).\nIn some examples we computed the distribution of Z = g(X"}, {"path": ".data\\docs\\ECE 203\\29_joint_dist_rv8.pdf", "chunk_id": 1, "text": "y1, y2).\n• g1 and g2 have continuous partial derivates such that\nJ(x1, x2) =\n\f\f\f\f\f\f\n∂g1\n∂x1\n∂g1\n∂x2\n∂g2\n∂x1\n∂g2\n∂x2\n\f\f\f\f\f\f\n= ∂g1\n∂x1\n∂g2\n∂x2\n−∂g1\n∂x2\n∂g2\n∂x1\n̸= 0\n\nThen, the pdf of Y1 and Y2 can be sh"}, {"path": ".data\\docs\\ECE 203\\29_joint_dist_rv8.pdf", "chunk_id": 2, "text": "Y2(y1, y2) = 1\n2fX1X2\n\u00121\n2y1 + 1\n2y2, 1\n2y1 −1\n2y2\n\u0013\n(29.2)\nExample 29.2: Let R and Θ be two random variables with joint pdf fRΘ(r, θ).\nConsider the change of variables\nX = R cos Θ\nY = R sin Θ.\nFind f"}, {"path": ".data\\docs\\ECE 203\\29_joint_dist_rv8.pdf", "chunk_id": 3, "text": "here h2(x, y) is the angle of the vector (x, y).\n\nComputing the Jacobian determinant\nJ(r, θ) =\n\f\f\f\f\f\f\n∂g1\n∂r\n∂g1\n∂θ\n∂g2\n∂r\n∂g2\n∂θ\n\f\f\f\f\f\f\n=\n\f\f\f\f\ncos θ\n−r sin θ\nsin θ\nr cos θ\n\f\f\f\f\n= r cos2 θ + r sin2 θ\n"}, {"path": ".data\\docs\\ECE 203\\30_prop_expt1.pdf", "chunk_id": 0, "text": "30. Properties of Expectations\nExpectation of Sums of Random Variables [Ross S7.2]\nRecall that the mean value of X is\nE[X] =\n\n\n\n\n\n\n\nP\nx xpX(x)\nX is discrete\nR ∞\n−∞xfX(x)dx\nX is continuous\nPropo"}, {"path": ".data\\docs\\ECE 203\\30_prop_expt1.pdf", "chunk_id": 1, "text": "fXY (x, y) =\n(\n1\nL2\n0 < x < L, 0 < y < L\n0\nelse\nWe want\nE[|X −Y |] =\nZ ∞\n−∞\nZ ∞\n−∞\n|x −y|fXY (x, y)dxdy\n= 1\nL2\nZ L\n0\nZ L\n0\n|x −y|dxdy\n\nNow\nZ L\n0\n|x −y|dx =\nZ y\n0\n(y −x)dx +\nZ L\ny\n(x −y)dx\n= L2\n2 + y2 "}, {"path": ".data\\docs\\ECE 203\\30_prop_expt1.pdf", "chunk_id": 2, "text": "by induction, E[X1 + · · · + Xn] = E[X1] + · · · + E[Xn].\nExample 30.3: Let X1, X2, . . . , Xn be iid with (common) mean µ. The\n\nquantity\n¯X = 1\nn\nn\nX\ni=1\nXi\nis called the sample mean. What is E[ ¯X]?"}, {"path": ".data\\docs\\ECE 203\\30_prop_expt1.pdf", "chunk_id": 3, "text": "he expected number of targets not hit.\nSolution:\n\nLet\nXi =\n(\n1\ntarget i not hit\n0\nelse\nX = # targets not hit = X1 + · · · + X10\nEach person independently hits target i with probability p/10.\nSo\nP[Xi ="}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 0, "text": "31. Properties of Expectations\nCovariance, Variance of Sums [Ross S7.4]\nProposition 31.1 If X and Y are independent, then for any functions g(x)\nand h(y):\ni)\nE[g(X)h(Y )] = E[g(X)]E[h(Y )]\nii)\ng(X) an"}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 1, "text": " single random variable X, its mean and variance give us some informa-\ntion about X.\n\nFor two random variables X and Y , covariance (and correlation) will give\nus information about the relationship be"}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 2, "text": "+ E[X]E[Y ]\n= E[XY ] −E[X]E[Y ]\nNote: If X and Y are independent, then E[XY ] = E[X]E[Y ]\nso Cov[X, Y ] = 0.\nExample 31.1: Does Cov[X, Y ] = 0 imply X and Y are independent?\nSolution: No!\nLet P[X = 0]"}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 3, "text": "µY )] = aCov[X, Y ] = Cov[X, aY ]\niv) Cov\n\n\nn\nX\ni=1\nXi,\nm\nX\nj=1\nYj\n\n=\nn\nX\ni=1\nm\nX\nj=1\nCov[Xi, Yj]\nWhy?\nFor iv), let\nU =\nn\nX\ni=1\nXi\nV =\nm\nX\nj=1\nYi\nE[Xi] = µi\nE[Yj] = νj\nThen:\nE [U] =\nn\nX\ni=1\nµi\nE ["}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 4, "text": "X\nj=1\nCov[Xi, Xj]\nby iv) of Prop. 31.2\n=\nX\ni,j\nj=i\nCov[Xi, Xj] +\nX\ni,j\nj̸=i\nCov[Xi, Xj]\n=\nn\nX\ni=1\nV ar[Xi] +\nX\ni,j\nj̸=i\nCov[Xi, Xj]\nby ii) of Prop. 31.2\n=\nn\nX\ni=1\nV ar[Xi] + 2\nX\ni,j\ni<j\nCov[Xi, Xj]\nby"}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 5, "text": "]\n= np(1 −p)\nExample 31.3: Recall (from Example 30.3) that ¯X = 1\nn\nPn\ni=1 Xi is called\nthe sample mean. Let\nS2 =\n1\nn −1\nn\nX\ni=1\n(Xi −¯X)2\nbe the sample variance.\nLet X1, . . . , Xn be iid with (commo"}, {"path": ".data\\docs\\ECE 203\\31_prop_expt2.pdf", "chunk_id": 6, "text": "\n}\nn( ¯\nX−µ)\n=\nn\nX\ni=1\n(Xi −µ)2 + n( ¯X −µ)2 −2n( ¯X −µ)( ¯X −µ)\n=\nn\nX\ni=1\n(Xi −µ)2 −n( ¯X −µ)2\nHence\n(n −1)E[S2] = E\n\" n\nX\ni=1\n(Xi −µ)2\n#\n−nE[( ¯X −µ)2]\n=\nn\nX\ni=1\nE[(Xi −µ)2] −nV ar[ ¯X]\n= nσ2 −nσ2\nn"}, {"path": ".data\\docs\\ECE 203\\32_prop_expt3.pdf", "chunk_id": 0, "text": "32. Properties of Expectations\nCorrelation [Ross S7.4]\nThe correlation [coefficient] of two random variables X and Y is defined as\nρ(X, Y ) =\nCov[X, Y ]\np\nV ar[X] V ar[Y ]\nProposition 32.1 −1 ≤ρ(X, Y "}, {"path": ".data\\docs\\ECE 203\\32_prop_expt3.pdf", "chunk_id": 1, "text": "] = 0, then P[Z = some constant\n|\n{z\n}\nE[Z]\n] = 1.\nIf ρ(X, Y ) = 1, then (32.1) + (32.2) imply\nV ar\n\u0014 X\nσX\n−Y\nσY\n\u0015\n= 0\nhence\nX\nσX\n−Y\nσY\n= µX\nσX\n−µY\nσY\nand therefore\nY = µY + σY\nσX\n(X −µX)\nIf ρ(X, Y ) "}, {"path": ".data\\docs\\ECE 203\\32_prop_expt3.pdf", "chunk_id": 2, "text": "egatively correlated.\nIf ρ(X, Y ) = 0 then X and Y are called uncorrelated.\nExample 32.1: [Matlab] For a bivariate Gaussian with parameters µX, µY ,\nσX, σY and ρ, it turns out that ρ is the correlatio"}, {"path": ".data\\docs\\ECE 203\\32_prop_expt3.pdf", "chunk_id": 3, "text": "plot(x(:,1), x(:,2), ’x’)\nThe plots below are for various values of ρ:\n\n-4\n-2\n0\n2\n4\nx\n-4\n-3\n-2\n-1\n0\n1\n2\n3\n4\ny\n = 0.0\n-4\n-2\n0\n2\n4\nx\n-3\n-2\n-1\n0\n1\n2\n3\n4\ny\n = 0.5\n-4\n-2\n0\n2\n4\nx\n-3\n-2\n-1\n0\n1\n2\n3\n4\ny\n = -0."}, {"path": ".data\\docs\\ECE 203\\33_prop_expt4.pdf", "chunk_id": 0, "text": "33. Properties of Expectations\nConditional Expectation [Ross S7.5]\nRecall that for 2 discrete random variables X and Y with P[Y = y] > 0:\npX|Y (x|y) = P[X = x|Y = y]\n= pXY (x, y)\npY (y)\nWe can define "}, {"path": ".data\\docs\\ECE 203\\33_prop_expt4.pdf", "chunk_id": 1, "text": "Y (x|y) = fXY (x, y)\nfY (y)\n=\n(\n1\nye−x/y\nx > 0\n0\nelse\nSo,\nE[X|Y = y] =\nZ ∞\n0\nx\ny e−x/ydx = y\nNote: Conditional expectations satisfy all the properties of ordinary expecta-\ntion, e.g.,\nE[g(X) | Y = y] "}, {"path": ".data\\docs\\ECE 203\\33_prop_expt4.pdf", "chunk_id": 2, "text": " = y]pY (y)\n[discrete case]\nE[X] =\nZ ∞\n−∞\nE[X|Y = y]fY (y)dy\n[continuous case]\nWhy? [Continuous Case]\nZ ∞\n−∞\nE[X|Y = y]fY (y)dy =\nZ ∞\n−∞\n\u0014Z ∞\n−∞\nxfX|Y (x|y)dx\n\u0015\nfY (y)dy\n=\nZ ∞\n−∞\nZ ∞\n−∞\nxfX|Y (x|y)fY "}, {"path": ".data\\docs\\ECE 203\\33_prop_expt4.pdf", "chunk_id": 3, "text": "ected time until you leave\nthe building?\nSolution: Let X = time to leave building, and Y = first door choice.\n\nE[X] = E[X|Y = 1]P[Y = 1]\n+ E[X|Y = 2]P[Y = 2]\n+ E[X|Y = 3]P[Y = 3]\n= 1\n3(E[X|Y = 1] + E["}, {"path": ".data\\docs\\ECE 203\\33_prop_expt4.pdf", "chunk_id": 4, "text": " amount spent in the store in one day? [Hard]\nSolution:\nLet Xi = amount spent by ith customer.\n\nTotal amount spent is Y = PN\ni=1 Xi.\nE\n\" N\nX\ni=1\nXi\n#\n= E\n\"\nE\n\"\nN\nX\ni=1\nXi\n\f\f\f\f\fN\n# #\nand\nE\n\"\nN\nX\ni=1\nXi"}, {"path": ".data\\docs\\ECE 203\\34_prop_expt5.pdf", "chunk_id": 0, "text": "34. Properties of Expectations\nComputing Probabilities by Conditioning\nWe can use conditioning to compute probabilities:\nLet A be an event.\nLet random variable Y ∈{y1, y2, . . .} and Bi = {Y = yi}.\nTh"}, {"path": ".data\\docs\\ECE 203\\34_prop_expt5.pdf", "chunk_id": 1, "text": "\nFind P[X < Y ].\nSolution: Method 1:\nP[X < Y ] =\nZZ\nx<y\nfX(x)fY (y)dxdy\n=\nZ ∞\n−∞\nZ y\n−∞\nfX(x)fY (y)dxdy\n=\nZ ∞\n−∞\nFX(y)fY (y)dxdy\n\nMethod 2:\nP[X < Y ] =\nZ ∞\n−∞\nP[X < Y | Y = y]fY (y)dy\n=\nZ ∞\n−∞\nP[X < y"}, {"path": ".data\\docs\\ECE 203\\34_prop_expt5.pdf", "chunk_id": 2, "text": "a −y)fY (y)dy\nand, taking derivatives:\nfX+Y (a) = d\ndaP[X + Y ≤a]\n\n= d\nda\nZ ∞\n−∞\nFX(a −y)fY (y)dy\n=\nZ ∞\n−∞\nd\ndaFX(a −y)fY (y)dy\n=\nZ ∞\n−∞\nfX(a −y)fY (y)dy"}, {"path": ".data\\docs\\ECE 203\\35_prop_expt6.pdf", "chunk_id": 0, "text": "35. Properties of Expectations\nConditional Variance [Ross S7.5.4]\nSo far, we have defined expectation, variance, and conditional expectation.\nWe now define the conditional variance\nV ar[X|Y ] = E[X2|Y"}, {"path": ".data\\docs\\ECE 203\\35_prop_expt6.pdf", "chunk_id": 1, "text": " Formula:\nE[ V ar[X|Y ] ] + V ar[ E[X|Y ] ] = E[X2] −(E[X])2\n= V ar[X]\nExample 35.1: Let X1, X2, · · · be iid and independent of the non-negative\n\ninteger random variable N. Let’s compute\nV ar\n\" N\nX\ni"}, {"path": ".data\\docs\\ECE 203\\35_prop_expt6.pdf", "chunk_id": 2, "text": "\n⇒V ar\n\" N\nX\ni=1\nXi\n\f\f\f\f\fN\n#\n= NV ar[X1]\n\nBy the conditional variance formula:\nV ar\n\" N\nX\ni=1\nXi\n#\n= E [ NV ar[X1] ] + V ar [ NE[X1] ]\n= E[N]V ar[X1] + (E[X1])2V ar[N]"}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 0, "text": "36. Properties of Expectations\nMoment Generating Functions [Ross S7.7]\nDefinition 36.1: The moment generating function (MGF) MX(t) of a ran-\ndom variable X is\nMX(t) = E[etX]\n=\n\n\n\n\n\n\n\nP\nx etxpX("}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 1, "text": "t) = nth derivative of f(t)]\nHence\nM ′\nX(0) = E[X]\nM (n)\nX (0) = E[Xn]\n\nExample 36.1: Find MX(t) if X ∼Poisson(λ). Use this to find E[X],\nE[X2] and V ar[X].\nSolution:\nMX(t) = E[etX]\n=\n∞\nX\nn=0\netnpX(n)"}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 2, "text": ". Then Z ∼N(0, 1) and:\nMZ(t) = E[etZ]\n=\nZ ∞\n−∞\netzfZ(z)dz\n=\n1\n√\n2π\nZ ∞\n−∞\netze−z2/2dz\n=\n1\n√\n2π\nZ ∞\n−∞\nexp\n\u0012\n−z2 −2zt\n2\n\u0013\ndz\n=\n1\n√\n2π\nZ ∞\n−∞\nexp\n\u0012\n−(z −t)2\n2\n+ t2\n2\n\u0013\ndz\n= et2/2\n1\n√\n2π\nZ ∞\n−∞\nexp\n\u0012\n−(z"}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 3, "text": "Random Variables [Ross S7.7]\nLet X and Y be independent random variables:\nMX+Y (t) = E\nh\net(X+Y )i\n= E\n\u0002\netXetY \u0003\n= E\n\u0002\netX\u0003\nE\n\u0002\netY \u0003\n[since X and Y are independent]\n= MX(t)MY (t)\nAnother useful fact"}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 4, "text": "+ λ2).\nExample 36.4: Let X ∼N(µX, σ2\nX) and Y ∼N(µY , σ2\nY ) be independent.\nWhat is the distribution of X + Y ?\nSolution:\nMX+Y (t) = MX(t)MY (t)\n= exp\n\u0012 t2σ2\nX\n2\n+ µXt\n\u0013\nexp\n\u0012 t2σ2\nY\n2\n+ µY t\n\u0013\n= exp"}, {"path": ".data\\docs\\ECE 203\\36_prop_expt7.pdf", "chunk_id": 5, "text": ", . . . , Xn are independent then:\nM(t1, t2, . . . , tn) = E\n\u0002\net1X1+t2X2+···+tnXn\u0003\n= E\n\u0002\net1X1\u0003\nE\n\u0002\net2X2\u0003\n· · · E\n\u0002\netnXn\u0003\n= MX1(t1)MX2(t2) · · · MXn(tn)\nSince the joint MGF uniquely specifies the j"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 0, "text": "37. Properties of Expectations\nMultivariate Normal Random Variables [Ross S7.8]\nDefinition of Multivariate Normal\nLet Z1, Z2, . . . , Zn be independent ∼N(0, 1).\nThen, define X1, X2, . . . , Xm by\nX1 "}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 1, "text": "\n|\n{z\n}\nA\n\n\n\n\n\nZ1\nZ2\n...\nZn\n\n\n\n\n\n|\n{z\n}\nZ\n+\n\n\n\n\n\nµ1\nµ2\n...\nµm\n\n\n\n\n\n|\n{z\n}\nµ\nNow, let B be a k × m matrix, and ν a column vector of length k. Then\nY = BX + ν\n= B(AZ + µ) + ν\n= (BA)Z"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 2, "text": "= V ar[ai1Z1 + · · · + ainZn + µi]\n= V ar[ai1Z1 + · · · + ainZn]\n= a2\ni1V ar[Z1] + · · · + a2\ninV ar[Zn]\n= a2\ni1 + · · · + a2\nin\nA single Gaussian random variable U is uniquely specified by:\n• its mea"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 3, "text": "random variables X1, . . . , Xm, it is common to define:\nX =\n\n\n\n\n\nX1\nX2\n...\nXm\n\n\n\n\n\n[random vector]\nµ = E[X] =\n\n\n\n\n\nE[X1]\nE[X2]\n...\nE[Xm]\n\n\n\n\n\n[mean vector]\nΣ = E[(X −µ)(X −µ)T ]\n["}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 4, "text": "[Xm, X2]\n· · ·\nCov[Xm, Xm]\n\n\n\n\n\n\nFor special bivariate case of X = (X1, X2)T :\nΣ = E[(X −µ)(X −µ)T ]\n= E[\n\u0012 (X1 −µ1)(X1 −µ1)\n(X1 −µ1)(X2 −µ2)\n(X2 −µ2)(X1 −µ1)]\n(X2 −µ2)(X2 −µ2)\n\u0013\n]\n=\n\u0012 Cov[X1, X1"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 5, "text": "(µ, Σ).\nIt can be shown that if Σ is invertible, then\nfX(x) =\n1\np\n(2π)m|Σ|\ne−1\n2 (x−µ)Σ−1(x−µ)\nNote: as expected, this depends only on µ and Σ.\nCovariance Matrix\n\nSay Z1, . . . , Zn are independent ∼N"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 6, "text": "atrix ΣX.\nLet B be a matrix, and ν a column vector.\nLet Y = BX + ν. Then\nµY = E[Y ] = E[BX + ν] = BE[X] + ν = BµX + ν\nΣY = E[Y Y T ] −µY µT\nY\n= E[(BX + ν)(BX + ν)T ] −µY µT\nY\n= E[BXX T BT + BXν T + νX"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 7, "text": "ΣXBT\nNot all square matrices can be covariance matrices.\nBelow, is a general condition.\nProposition 37.1 a) A covariance matrix Σ is i) symmetric and ii) positive\nsemi-definite.\nb) Any matrix Σ that i"}, {"path": ".data\\docs\\ECE 203\\37_prop_expt8.pdf", "chunk_id": 8, "text": "D is\ndiagonal.\nThe diagonal entries of D are ≥0 since it Σ is positive semi-definite.\nThen Σ = UD1/2D1/2U T .\nLet A = UD1/2.\nThen\nΣX = AΣZAT\n= AAT\n= UD1/2(UD1/2)T\n= UD1/2(D1/2)T U T\n= UD1/2D1/2U T\n= Σ"}, {"path": ".data\\docs\\ECE 203\\38_limit_thms1.pdf", "chunk_id": 0, "text": "38. Limit Theorems\nChebyshev’s inequality and Weak Law of Large Numbers [Ross S8.2]\nProposition 38.1 (Markov inequality) If X is a non-negative random vari-\nable, then for any a > 0:\nP[X ≥a] ≤E[X]\na\nW"}, {"path": ".data\\docs\\ECE 203\\38_limit_thms1.pdf", "chunk_id": 1, "text": "en for any b > 0:\nP [|X −µ| ≥b] = P\n\u0002\n(X −µ)2 ≥b2\u0003\n≤σ2\nb2\nWhy?\n(X −µ)2 is a non-negative random variable. With b2 > 0, apply Markov’s\ninequality to it:\nP\n\u0002\n(X −µ)2 ≥b2\u0003\n≤E\n\u0002\n(X −µ)2\u0003\nb2\n= σ2\nb2\nNote: "}, {"path": ".data\\docs\\ECE 203\\38_limit_thms1.pdf", "chunk_id": 2, "text": " what can you say about the\nprobability that it produces more than 40 but fewer than 60 items?\nSolution: Let X be the number of items produced in a week.\n\na) By Markov\nP[X ≥75] ≤E[X]\n75\n= 50\n75 = 2\n3\n"}, {"path": ".data\\docs\\ECE 203\\38_limit_thms1.pdf", "chunk_id": 3, "text": "] = P[{0 ≤X ≤1} ∪{9 ≤X ≤10}]\n= 0.20\n\nChebyshev can be used to prove theoretical results:\nProposition 38.3 Weak Law of Large Numbers [WLLN]\nLet X1, X2, . . ., be a sequence of iid random variables with"}, {"path": ".data\\docs\\ECE 203\\38_limit_thms1.pdf", "chunk_id": 4, "text": "side and a 1 on the other.\nYou conduct a sequence of independent trials that consists of repeatedly flip-\nping the coin.\n\nLet Zn be the fraction of flips that result in the number 1 after n flips.\nWha"}, {"path": ".data\\docs\\ECE 203\\39_limit_thms2.pdf", "chunk_id": 0, "text": "39. Limit Theorems\nThe Central Limit Theorem (CLT) [Ross 8.3]\nProposition 39.1 The Central Limit Theorem\nLet X1, X2, . . . be a sequence of iid random variables having mean µ and\nvariance σ2. Then, th"}, {"path": ".data\\docs\\ECE 203\\39_limit_thms2.pdf", "chunk_id": 1, "text": ", X2, . . . of the\ndistance of a star.\nEach Xi has mean µ (the true distance) and variance σ2 = 4 light-years2.\n\nHow many measurements are needed to be 95% certain that the sample aver-\nage ¯X of the "}, {"path": ".data\\docs\\ECE 203\\39_limit_thms2.pdf", "chunk_id": 2, "text": " Table [Notes #18], √n/4 ≥1.96.\nThe smallest integer than makes this true is n = 62.\nNote: This analysis assumes that with 62 observations, Zn is well approxi-\nmated by a Gaussian. In statistics, n ≥3"}, {"path": ".data\\docs\\ECE 203\\39_limit_thms2.pdf", "chunk_id": 3, "text": "µ\nS\n=\n¯X −µ\nS/√n\n(39.2)\nIf X ∼N(µ, σ2), then Tn has Student-t distribution with n −1 degrees of\nfreedom:\n• pdf of Tn depends on n but not µ or σ\n• pdf of Tn similar to N(0, 1) but has heavier tails\n• "}, {"path": ".data\\docs\\ECE 203\\39_limit_thms2.pdf", "chunk_id": 4, "text": "α = 0.05:\n\nn\ntα/2\n16\n2.131\n30\n2.045\n40\n2.021\n62\n2.000\n120\n1.980\n1000\n1.962\nIf n →∞then tα/2 →zα/2 = 1.960\nLarge Sample Confidence Interval: If Xi are not Gaussian or σ not known,\nwhen n large enough ("}, {"path": ".data\\docs\\ECE 203\\mgf_table.pdf", "chunk_id": 0, "text": "Common Random Variables:\n• X ∼Binomial(n, p): 0 ≤p ≤1, n ∈{1, 2, . . .}\npX(k) =\n\u0012n\nk\n\u0013\npk(1 −p)n−k\nk ∈{0, 1, . . . , n}\nE[X] = np\nV ar[X] = np(1 −p)\nMX(t) = (pet + 1 −p)n\n• X ∼Geometric(p): 0 ≤p ≤1\npX"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 0, "text": "Table of Φ(x):\nx\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\n0.0\n0.50000\n0.50399\n0.50798\n0.51197\n0.51595\n0.51994\n0.52392\n0.52790\n0.53188\n0.53586\n0.1\n0.53983\n0.54380\n0.54776\n0.55172\n0.55567\n0.559"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 1, "text": "04\n0.72240\n0.6\n0.72575\n0.72907\n0.73237\n0.73565\n0.73891\n0.74215\n0.74537\n0.74857\n0.75175\n0.75490\n0.7\n0.75804\n0.76115\n0.76424\n0.76730\n0.77035\n0.77337\n0.77637\n0.77935\n0.78230\n0.78524\n0.8\n0.78814\n0.79103\n0"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 2, "text": ".89435\n0.89617\n0.89796\n0.89973\n0.90147\n1.3\n0.90320\n0.90490\n0.90658\n0.90824\n0.90988\n0.91149\n0.91309\n0.91466\n0.91621\n0.91774\n1.4\n0.91924\n0.92073\n0.92220\n0.92364\n0.92507\n0.92647\n0.92785\n0.92922\n0.93056\n0"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 3, "text": "93\n0.97257\n0.97320\n0.97381\n0.97441\n0.97500\n0.97558\n0.97615\n0.97670\n2.0\n0.97725\n0.97778\n0.97831\n0.97882\n0.97932\n0.97982\n0.98030\n0.98077\n0.98124\n0.98169\n2.1\n0.98214\n0.98257\n0.98300\n0.98341\n0.98382\n0.984"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 4, "text": "06\n0.99520\n2.6\n0.99534\n0.99547\n0.99560\n0.99573\n0.99585\n0.99598\n0.99609\n0.99621\n0.99632\n0.99643\n2.7\n0.99653\n0.99664\n0.99674\n0.99683\n0.99693\n0.99702\n0.99711\n0.99720\n0.99728\n0.99736\n2.8\n0.99744\n0.99752\n0"}, {"path": ".data\\docs\\ECE 203\\phi_table.pdf", "chunk_id": 5, "text": ".99942\n0.99944\n0.99946\n0.99948\n0.99950\n3.3\n0.99952\n0.99953\n0.99955\n0.99957\n0.99958\n0.99960\n0.99961\n0.99962\n0.99964\n0.99965\n3.4\n0.99966\n0.99968\n0.99969\n0.99970\n0.99971\n0.99972\n0.99973\n0.99974\n0.99975\n0"}, {"path": ".data\\docs\\ECE 207\\Chapter 1.pdf", "chunk_id": 0, "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 0, "text": "ECE 208 Lecture Notes\nbased on\nMathematical Logic for Computer Science\n(Third Revised Edition)\nSpringer, 2012\nMordechai (Moti) Ben-Ari\nhttp://www.weizmann.ac.il/sci-tea/benari/\nc⃝2012 by Springer.\n1\n\n"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 1, "text": " diﬀerence?\n– Boolean algebra focuses on operations: AND, OR, NOT, etc. . . .\n– historically, logic focuses on formal proof :\n∗deﬁned by the rules of a deductive system;\n∗formal in the sense that the "}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 2, "text": " SAT;\n– ‘SAT-solver’ tools have useful applications to other constraint-\nsatisfaction problems, such as package management.\n• Propositional logic extends to predicate logic – or ﬁrst-order logic\n– wit"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 3, "text": " predicate logic, are theorems of arithmetic.\n• The textbook uses →, ←, and ↔; we’ll stick with ⇒, ⇐, and ⇐⇒.\n• Predicate logic is used, for example,\n– in databases,\n– in ‘satisﬁability modulo theory’"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 4, "text": " the future;\n– ♦p – ‘eventually p’: p is true either now or at some future time.\n– pUq – ‘p until q’: until q becomes true, p will be true.\n• Allows for ‘temporal reasoning’:\n– □(p =⇒⃝p) =⇒□(p =⇒□p):\n"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 5, "text": "tually true.\n– pUq ⇐⇒q ∨(p ∧⃝(pUq))\n• Temporal logic is used, for example, in the formal veriﬁcation of con-\ncurrent systems:\n– system modelled as a collection of interacting ﬁnite state machines\n(say"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 6, "text": "-invalidate: when one processor writes to memory,\nmark other caches’ corresponding entries as invalid (sav-\ning BW);\n– 2 key architectures:\nSnooping: based on common read/write bus, and monitor-\ning ("}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 7, "text": "he\nstate of block B changes to modiﬁed in that cache, and (via\nbus snooping) to invalid in other caches (and in the main\nmemory);\n– processor P can then continue to read from and write to that\nblock;\n"}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 8, "text": "hey both contain the up-to-date value,\nas now does the main memory;\n– if other processors request the contents of the block, they\nwill be read from memory, and the block will take the value\nshared in "}, {"path": ".data\\docs\\ECE 208\\ece208_notes_ch1.pdf", "chunk_id": 9, "text": "f processor P writes x to block B, then any read\nof block B (from any cache) yields x, until there’s another write\nto block B.\n6\n\n5G networks\n– Increased speed due to storage of data ‘closer’ to subsc"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 0, "text": "Chapter 2: Propositional Logic:\nSyntax, Semantics\nThis chapter concerns syntax and semantics of propositional logic. In prin-\nciple, these subjects have been seen in ECE 108. However, the chapter will"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 1, "text": ", r, . . . , possi-\nbly with subscripts.\n• Boolean operators:\nnegation ¬\ndisjunction ∨\nconjunction ∧\nimplication =⇒\nequivalence ⇐⇒\nnor ↓\nnand ↑.\nNegation is a unary operator, while the others are bina"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 2, "text": "ormulas of\npropositional logic can be deﬁned recursively as trees:\n• a leaf labelled by an atomic proposition is a formula;\n• a node labelled by ¬ with a single child that is a formula is itself a\nfor"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 3, "text": "∧(q ∧(r ∧. . . a formula?\nHere are two examples of formulas:\np\nq\n\n\n\nJJJ\n=⇒\np\n¬\nq\n¬\n\n\n\nJJJ\n=⇒\n#\n#\n#\nccc\n⇐⇒\np\nq\np\nq\n¬\n\n\n\nJJJ\n=⇒\n¬\n#\n#\n#\nJJJ\n⇐⇒\n\b\n\b\n\b\n\b\n\b\nJJJ\n=⇒\nFigure 2.1: Two formulas.\n2\n\nFormulas as s"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 4, "text": "r(F1)\nwrite the label of the root of F\nInorder{F2}\n(If the root of F is labelled by the unary operator ¬, the left subtree is\nconsidered to be the empty tree, and the step Inorder(F1) is skipped.)\nAs "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 5, "text": "then =⇒, then q, then\n⇐⇒, and so on, getting\np =⇒q ⇐⇒¬p =⇒¬q .\n□\n3\n\n2.1.3 Resolving ambiguity in the string representation\nThere are (at least) three means of resolving this ambiguity: parentheses,\npr"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 6, "text": "er(F1)\nwrite the label of the root of F\nInorder{F2}\nwrite a right parenthesis ’ ) ’\n(If the root of F is labelled by the unary operator ¬, the left subtree is\nconsidered to be the empty tree, and the "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 7, "text": "ce and associa-\ntivity conventions.\nSuppose that the order of precedence of operations (from high to low) is\nas follows:\n¬\n∧, ↑\n∨, ↓\n=⇒\n⇐⇒, ⊕\nSuppose also that operators ‘associate to the right’: for "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 8, "text": "ation is based an a preorder traversal of the tree:\n1Actually, it was developed by one Polish logician, Jan  Lukasiewicz. But rather than\nattempt to pronounce his name, people simply called it Polish "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 9, "text": "ft sub-\ntree is considered to be the empty tree, and the step Preorder(F1) is\nskipped.)\nExample 2.9: In Polish notation, the two formulas of Figure 2.1 are respec-\ntively:\n⇐⇒=⇒p q\n=⇒¬ p ¬ q , and\n=⇒p "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 10, "text": "he tree consisting of a leaf labelled\nby p,” and\n6\n\nImplies to mean,\n“pop the two subtrees F1 and F2 from the top of the stack, and then\npush onto the stack the tree whose root is labelled =⇒, and who"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 11, "text": "that of ¬q below. After the following operation,\nthe tree representation of p =⇒¬q (in conventional, inﬁx notation) is at\nthe top of the stack, and so forth.\nIn fact, Polish notation, or reverse Polis"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 12, "text": "s always the same: when\nyou encounter an operand, push it onto the stack; when you encounter an\noperator, pop the requisite sequence of operands from the stack, apply the\noperator to them, and push th"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 13, "text": "ction\n• We performed mathematical induction on the natural numbers in ECE\n108, and also saw examples of other kinds of induction.\n• Generally, induction is a means of extending an argument from ‘simpl"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 14, "text": "n on the ‘height’ of trees.\nTheorem 2.12 (Structural induction): Given a property of formulas and\na formula A ∈F, suppose that,\n1. the property holds for all atoms p in A;\n2. for any subformula of A o"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 15, "text": "f the root of the tree is\nlabelled by a logical operator, deﬁne its height to be one greater than that\nof the highest subtree rooted at one of its children.\n8\n\nProof: Assume that the three assumptions"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 16, "text": "hat height of A is n > 0, and that the Theorem\nholds for formulas of lesser height. Then A is either of the form ¬F\nor of the form F1 op F2.\nIn the ﬁrst case, the height of F is n −\n1, so the Theorem "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 17, "text": "d F2, both F1 and F2 satisfy\nthe property; but then, by assumption 3, F1opF2 = A also satisﬁes the\nproperty. The Theorem therefore holds for A.\nThis completes the induction.\n□\nThe above is a stronger "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 18, "text": "s correct under the standard rules of precedence.\nTo prove that the formula has the property, we show that the three as-\nsumptions of the theorem are satisﬁed. For this, denote by SR(F) the string\nrep"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 19, "text": "\n3. If F1opF2 is a subformula of A, then note, owing to the structure of A,\nthat op is of strictly lower precedence than any operators in F1 or F2.\nIt follows that, if SR(F1) and SR(F2) are correct st"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 20, "text": "A ∈F be a formula and let PA be the set of atoms\nappearing in A. An interpretation for A is a total function IA\n: PA →\n{T, F} that assigns a truth value T or F to each atom in A.\nDeﬁnition 2.16 Let IA"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 21, "text": "\nA1 ↑A2\notherwise\nT\nA1 ↓A2\nF\nF\nT\nA1 ↓A2\notherwise\nF\nA1 ↔A2\nv(A1) = v(A2)\nT\nA1 ↔A2\nv(A1) ̸= v(A2)\nF\nA1 ⊕A2\nv(A1) ̸= v(A2)\nT\nA1 ⊕A2\nv(A1) = v(A2)\nF\nFigure 2.3: Truth values of formulas\n10\n\nPartial inter"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 22, "text": "– skipped\nThis material should be familiar from ECE 108 and ECE 124.\n2.2.3 Understanding the Boolean operators – skipped\nThis should also be familiar.\n2.2.4 An interpretation for a set of formulas\nDeﬁ"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 23, "text": "he truth values of the elements of S can be evaluated as:\nvI (p =⇒q) = F\nvI (p) = IS(p) = T\nvI (q ∧r) = F\nvI (p ∨s) = T\nvI (s ∧q) = F\nvI (p ∨s ⇐⇒s ∧q) = F .\nHere, the subscript on the I has been dropp"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 24, "text": "Theorem 2.28 Let A1, A2 ∈F. Then A1 ∨A2 ≡A2 ∨A1.\nProof: Let I be an arbitrary interpretation. If I is an interpretation for\nA1∨A2, then it is an interpretation for A2∨A1, and vice versa, because the t"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 25, "text": "bout it. That\nmeans that the above argument applies to any such interpretation I , and\ntherefore to all such interpretations.\n2.3.1 The relationship between ⇐⇒and ≡\nWe have called the Boolean operator"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 26, "text": "close relationship between the two:\nTheorem 2.29 A1 ≡A2 if and only if A1 ⇐⇒A2 is true in every inter-\npretation (of {A1, A2}).\nProof: Let I be an arbitrary interpretation of {A1, A2}. Then vI (A1) =\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 27, "text": "he same as B, then it is a proper subformula of B.\nExample 2.31 Figure 2.4 shows the left-hand formula from Figure 2.1 and\nits proper subformulas. Represented as strings, the formula\n(p =⇒q) ⇐⇒(¬p =⇒¬"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 28, "text": "sly replacing all occurrences of the subtree\nA in B with A′.\nExample 2.33 Let B be (p =⇒q) ⇐⇒(¬p =⇒¬q), A be p =⇒q,\nand A′ be ¬p ∨q. Then B{A ←A′} is\n(¬p ∨q) ⇐⇒(¬p =⇒¬q) .\n□\nNote: A could be a subform"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 29, "text": "ence of A, you would get\n((p ∨¬p) =⇒(p =⇒q)) ⇐⇒(¬p =⇒¬(p =⇒q))) .\nYou would then have to treat this formula with care, and substitute only\nfor the second occurrence of A. This is why we stress that th"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 30, "text": "the theorem, recursively deﬁne the depth of a node in a tree:\nif the node is the root, its depth is zero; otherwise, the node appears in a\nspeciﬁc subtree of the root, and its depth is deﬁned to be on"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 31, "text": " it can be shown that, for any subformula ˜B of B, ˜B{A ←A′}\nhas the same truth value as ˜B under I .\nThe proof is by induction on the greatest depth d in ˜B of any occurrence\nof A. (If there is no su"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 32, "text": " less than d, so by inductive hypothesis, all\nsuch subformulas have the same truth values under I before and after\nsubstitution. Therefore, ˜B and ˜B{A ←A′} also have the same truth\nvalue under I . Th"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 33, "text": " are left as exercises.\nAbsorption of constants\nExtend the language of propositional logic to include two ‘constant’ atomic\npropositions true and false. (Alternatively, one may use the respective sym-"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 34, "text": " formula\n‘collapses’ in such a way that a binary operator is no longer needed; it may\neven mean that the truth value of the formula itself is a constant:\nA ∨true\n≡\ntrue\nA ∧true\n≡\nA\nA ∨false\n≡\nA\nA ∧fal"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 35, "text": "mutativity, associativity and distributivity\nWith the exception of implication, the Boolean operators are commutative:\nA ∨B\n≡\nB ∨A\nA ∧B\n≡\nB ∧A\nA ↔B\n≡\nB ↔A\nA ⊕B\n≡\nB ⊕A\nA ↑B\n≡\nB ↑A\nA ↓B\n≡\nB ↓A\nMoreover,"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 36, "text": "tion and conjunction distribute over each other:\nA ∨(B ∧C)\n≡\n(A ∨B) ∧(A ∨C)\nA ∧(B ∨C)\n≡\n(A ∧B) ∨(A ∧C)\nIt will simplify some of our proofs if we can consider formulas to contain\nonly a small, but ‘ade"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 37, "text": " (¬ A ∨¬ B)\nA ∨B\n≡\n¬ A →B\nA ∧B\n≡\n¬ (A →¬ B)\nRecall from ECE 108 and ECE 124 that the ﬁfth and sixth of the above\nequivalences are called De Morgan’s laws.\n2.4 Sets of Boolean operators\nThis material s"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 38, "text": "unsatisﬁable if it is not satisﬁable – that is, iﬀvI (A) = F for all\ninterpretations I .\n• A is falsiﬁable, denoted ⊭A, if it is not valid – that is, iﬀvI (A) = F\nfor some interpretation I .\nThe inter"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 39, "text": "roof: Let I be an arbitrary interpretation for A (and therefore, for ¬A).\nThen\nvI (A) = T if and only if vI (¬A) = F .\n(1)\nThe formula A is valid if and only if the truth values in (1) hold for all I "}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 40, "text": " it terminates,\nand returns the answer yes if A ∈U and no if A ̸∈U .\nThe problem of ﬁnding a decision procedure is called a decision problem.\nThough Deﬁnition 2.40 is formulated speciﬁcally in terms o"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 41, "text": "on prob-\nlem is referred to as Boolean satisﬁability, or SAT. SAT is obviously\na decidable problem: it suﬃces to construct a truth table to solve it.\nHowever, that takes exponential time in the number"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 42, "text": "ely that any of them\ntake less than exponential time in the worst case (if any deterministic\npolynomial-time algorithm exists, then P = NP).\n19\n\n2.5.2 Satisﬁability of a set of formulas\nDeﬁnition 2.42"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 43, "text": "ot.\n□\nTheorem 2.44 If U = {Ai : i ∈I} ⊆F is satisﬁable, then so is U \\ {Ai},\nfor any i ∈I.\nTheorem 2.45 If U ⊆F is satisﬁable and B ∈F is valid, then U ∪{B}\nis satisﬁable.\nTheorem 2.46 If U ⊆F is unsa"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 44, "text": " of U is a model of A.\nIf U = ∅, then every interpretation is vacuously a model of U. In that\ncase, A is a logical consequence of U if and only if A is valid.\nTheorem 2.53 If U |= A, then U ∪U ′ |= A,"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 45, "text": " procedures). In the text-\nbook, they are used to unify the treatments of diﬀerent logics; and results on\ntableaux are leveraged to prove results about deductive systems. However,\npropositional resolu"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 46, "text": "ummary\n• This treatment of propositional logic will serve as a prototype for the\ntreatments of predicate and temporal logic.\n• First, the syntax is given, with formulas deﬁned unambiguously as\ntrees.\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch2.pdf", "chunk_id": 47, "text": "ll.\n• Two formulas are logically equivalent if they have the same truth values\nin all interpretations; in that case they can be substituted for each other\nwithout changing the truth values of formulas"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 0, "text": "Chapter 3: Deductive Systems\nDeﬁnition 3.1\nA deductive system – or proof system – consists of a set of formulas called\naxioms and a set of (formal) inference rules.\nA proof in such a system is a seque"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 1, "text": ", and the deductive system is sound\n(⊢A implies ⊨A).\n• If all valid formulas are theorems, the proof system is complete\n(⊨A implies ⊢A).\n• Deductive systems are particularly useful for logics where va"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 2, "text": "verview\n• Two common types of logical deductive systems, or proof systems, are\nHilbert and Gentzen systems.\n• Hilbert systems have many axioms and a single inference rule. Gentzen\nsystems feature fewe"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 3, "text": " system H\n• As usual, capital letters A, B, C, . . . will be used to represent arbitrary\nformulas of propositional logic.\n• Only the operators =⇒and ¬ will be used; others will be introduced\nonly as a"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 4, "text": "A =⇒((A =⇒A) =⇒A)\nAxiom 1\n3. ⊢(A =⇒(A =⇒A)) =⇒(A =⇒A)\nMP, 1, 2\n4. ⊢A =⇒(A =⇒A)\nAxiom 1\n5. ⊢A =⇒A\nMP, 3, 4\n□\nStrictly speaking, the three ‘axioms’ given above are really axiom schemes\nor schemas: a sub"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 5, "text": "ve to work largely from\nthe axioms and the inference rule themselves. But as the catalogue of proved\ntheorems grows, it becomes easier to formalize arguments on the basis of\nyour logical intuition.\nTh"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 6, "text": " been used in the proof of A (in addition to the axioms).\nIn other words, A can be deduced from the assumptions U by treating\nthe formulas in U as if they were axioms.\n• A proof of A from the set of a"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 7, "text": "nsitivity\nU⊢A→B\nU⊢B→C\nU⊢A→C\nExchange of antecedent\nU⊢A→(B→C)\nU⊢B→(A→C)\nDouble negation\nU⊢¬ ¬ A\nU⊢A\nReductio ad absurdum\nU⊢¬ A→false\nU⊢A\nWe shall prove the Deduction Rule. Note that this pattern of rea"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 8, "text": "length 1 of B from\nU ∪{A}. If B is an axiom, or B ∈U, then U ⊢B, and hence, U ⊢A =⇒B,\nby Axiom 1 and MP. Otherwise, B is A, in which case the result follows from\nTheorem 3.10. This completes the base "}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 9, "text": " ⊢A =⇒C and\n4\n\nU ⊢A =⇒(C =⇒B), so the result follows by Axiom 2, and two applications\nof MP.\nThe proofs of the other derived rules and theorems of H listed in the text-\nbook are good exercises. This i"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 10, "text": "erty of logical consequence, is called strong soundness.\nTheorem (Strong soundness) The Hilbert system H satisﬁes strong sound-\nness: if U ⊢A, then U ⊨A.\n(Soundness is the weaker property that every t"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 11, "text": "e converse – strong completeness – should also hold. Before\ndiscussing strong completeness, we should examine the important syntactical\nissue of consistency.\n3.7 Consistency\nDeﬁnition 3.42 Within a de"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 12, "text": "tent\nand suppose that U ⊢B and U ⊢¬B.\nIt can be shown that ⊢B\n=⇒\n(¬B\n=⇒\nA) (Theorem 3.21 of the\ntextbook). The result follows by two applications of MP.\n□\nCorollary 3.44 The set U is consistent iﬀfor "}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 13, "text": "hen A and ¬A are inter-\nchanged.)\nCorollary Let U ⊆F be consistent and A ∈F. Then either U ∪{A} or\nU ∪{¬A} is consistent.\nProof: If both sets are inconsistent, then by Theorem 3.45, U is inconsistent."}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 14, "text": " all inconsistent.\nTheorem (Henkin) Let S ⊆F be consistent. Then there exists a maxi-\nmal consistent S∗that contains S.\nProof: Because the set of atomic proposition symbols is countably inﬁnite,\nthe s"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 15, "text": "consistent: any proof of, say, false\nbased on S∗assumes only a ﬁnite number of elements of S∗; all such elements\nmust be contained in some Sk, but Sk is consistent – a contradiction.\nSuppose that S∗is"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 16, "text": "sitional formulas is satisﬁable if and only if it is\nconsistent.\nProof: Let S ⊆F be consistent, and let S∗be the maximal consistent set\n‘constructed’ in the proof of the preceding theorem. Deﬁne the i"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 17, "text": "(A) =\nT if and only if A ∈S∗. Indeed, the base case holds by the deﬁnition of I and\nthe consistency of S∗. For the induction step, suppose ﬁrst that A = ¬A1;\nthen\nvI (A) = T iﬀvI (A1) = F iﬀA1 ̸∈S∗iﬀA"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 18, "text": "set is satisﬁable if (and only if, by soundness) it is\nconsistent.\n□\n3.8 Strong completeness and compactness\nTheorem 3.47 (Strong completeness) Let U be a ﬁnite or countably in-\nﬁnite set of formulas,"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 19, "text": "every ﬁnite subset of S is satisﬁable. Then S\nis satisﬁable.\nProof outline: By the contrapositive. Suppose that S is not satisﬁable.\nThen, for any A, S ⊨A and S ⊨¬A. But then, by strong completeness, "}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 20, "text": "loped in order to formalize mathematical\nreasoning in the form of deductive systems.\n• Nearly all mathematical theories take the form of Hilbert systems like\nH :\n– a set of axioms,\n– Modus Ponens as t"}, {"path": ".data\\docs\\ECE 208\\notes_ch3.pdf", "chunk_id": 21, "text": "ms. In the next chapters, we shall study more eﬃcient algorithms\nand data structures than those based on truth tables for establishing\nsuch properties.\n11"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 0, "text": "Chapter 4\nPropositional Logic: Resolution\n• The method of resolution dates at least to a 1938 dissertation of Archie\nBlake on Boolean algebra, and was famously employed by Martin Davis\nand Hilary Putn"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 1, "text": "ve normal form’ . . .\n4.1 Conjunctive normal form\nA ‘normal form’ is a particular syntactical form into which any formula can\nbe transformed while preserving logical equivalence.\nDeﬁnition 4.1 A formu"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 2, "text": " Julia Robinson, who is also famous for work on logical decision\nprocedures, much of which was carried out in collaboration with Davis, Putnam, and\nothers.\n2In a precise technical sense concerning wor"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 3, "text": ":\nA ⇔B ≡\n(A ⇒B) ∧(B ⇒A)\nA ⊕B ≡¬(A ⇒B) ∨¬(B ⇒A)\nA ⇒B ≡¬A ∨B\nA ↑B ≡¬(A ∧B)\nA ↓B ≡¬(A ∨B)\n2. Drive negations inward via De Morgan’s laws:\n¬(A ∧B) ≡¬A ∨¬B\n¬(A ∨B) ≡¬A ∧¬B\nRepeat as long as possible, at wh"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 4, "text": "q)\n≡(¬¬¬p ∧¬¬q) ∨(¬p ∨q)\n≡(¬p ∧q) ∨(¬p ∨q)\n≡(¬p ∨¬p ∨q) ∧(q ∨¬p ∨q)\n(≡(¬p ∨q) ∧(¬p ∨q) ≡¬p ∨q)\n□\n4.2 Clausal form\n• a notational variant of conjunctive normal form.\nDeﬁnition 4.5\n• A clause is a set o"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 5, "text": "d ∅.\nCorollary 4.6 Every propositional formula can be transformed into a logi-\ncally equivalent formula in clausal form.\nProof: By Theorem 4.3, every φ ∈F can be transformed in to a logically\nequivale"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 6, "text": "sited:\n(¬p =⇒¬q) =⇒(p =⇒q) ≡(¬p ∨¬p ∨q) ∧(q ∨¬p ∨q)\n≡(¬p ∨q) ∧(¬p ∨q)\n≡¬p ∨q)\n≡{{¬p, q}} .\n□\nExample 4.7 The CNF formula\n(p ∨r) ∧(¬q ∨¬p ∨q) ∧(p ∨¬p ∨q ∨p ∨¬p) ∧(r ∨p)\nis logically equivalent to its c"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 7, "text": "if it contains a pair of clashing literals.\nSince a trivial clause is valid, its removal from a set of clauses preserves\nlogical equivalence.\nLemma 4.9 Let S be a set of clauses, and let C ∈S be a tri"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 8, "text": "ile the empty set of\nclauses, ∅is valid.\nRationale: Think of a disjunction as being satisﬁed when there exists a dis-\njunct that is satisﬁed; and a conjunction as satisﬁed whenever all conjuncts\nare s"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 9, "text": ".\nNotation\n• A clause {p, ¬q, r} will be abbreviated pqr, by eliminating the curly\nbraces and commas, and letting q stand for ¬q.\n• In this notation, the formula of example 4.7 becomes {pr, qpq, ppq}\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 10, "text": "p) = F ,\n– I (l) = F, if l = p and I (p) = T ,\n– I (l) = T, if l = p and I (p) = F .\nThe restriction of CNF to 3CNF\n– skipped, for brevity.\n5\n\n4.3 Resolution rule\n• When used for checking validity, re"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 11, "text": "lution rule.\n• The empty clause is eventually obtained if and only if the original set\nof clauses is unsatisﬁable.\nRule 4.14 (Resolution rule) Let C1, C2 be clauses such that l ∈C1, lc ∈\nC2. Then C1 a"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 12, "text": "als c and c. Their resolvent is\nC = (abc \\ c) ∪(bce \\ c) = ab ∪be = abe .\n□\nResolution is only performed if the pair of literals clash on exactly one\npair of complementary literals: otherwise, their r"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 13, "text": "an be deleted from a set of clauses without af-\nfecting its truth value, we do not perform resolution on clauses that clash on\nmore than one pair of literals.\nTheorem 4.17 The resolvent C is satisﬁabl"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 14, "text": "hat C is satisﬁed by some interpretation I for C.\nThen there must be some literal l′ ∈C1∪C2 other than l or lc that is satisﬁed\nby I . If, say, l′ ∈C1, then extend I to an interpretation for {C1, C2} "}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 15, "text": "w:\n• Choose a pair of clashing clauses {C1, C2} that has not been chosen\nbefore.\n• Compute C = Res(C1, C2) according to the resolution rule.\n• If C is not a trivial clause, let Si+1 = Si∪{C}; otherwis"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 16, "text": "ation is represented as a tree in Figure 4.1. The clauses of S\nlabel the leaves of the tree, and the resolvents label interior nodes whose\nchildren are the parent clauses of the resolution.\n□\n¯p\np\n¯p¯"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 17, "text": "ause □is unsatisﬁable, it follows by Theorem 4.17 that if there\nexists a resolution refutation of S then S is unsatisﬁable.\n• The set of clauses S of Example 4.19 is the clausal form of the nega-\ntion"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 18, "text": "tation procedure, soundness and completeness\nare better expressed in terms of unsatisﬁability, rather than validity.\nCorollary 4.22 (Soundness) Let S be a set of clauses. If there is a refu-\ntation by"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 19, "text": "ons\nappearing in S. A semantic tree is a complete binary tree such that, for every\n0 < i ≤n, every left-branching edge from a node at depth i −1 is labelled\npi, and every right-branching edge is label"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 20, "text": "etermines a branch.\n• The branch b is closed if the corresponding truth value vb(S) is F;\notherwise, b is open.\n• The tree T is closed if all branches are closed; otherwise, it is open.\n• The semantic"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 21, "text": "e failure\nnode.\n• Figure 4.3 shows the numbers of the clauses from Example 4.19 that\nare associated with the failure nodes of the set of clauses S of that\nexample.\n• A clause C associated with a failu"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 22, "text": "d the root, there must be\nfailure nodes that are siblings.\n10\n\nn\nn1\nn2\npi\npi\n\u0000\u0000\u0000\u0000@\n@\n@\n@\nFigure 4.4: Sibling failure nodes\n– Clauses associated with sibling failure nodes at depth i clash on\nthe singl"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 23, "text": "gure 4.3 shows the failure nodes of the set S and\nthe numbers of the associated clauses for Example 4.19.\nFor instance, clause 3, r, is associated with the failure node numbered 3,\nbecause {r} is a su"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 24, "text": " node becomes a failure\nnode after resolution of clauses 1 and 6.\nIn both cases, the resolvent is\nassociated with the failure node.\n□\n4.5 Hard examples for resolution\nWe’ll skip the details of this se"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 25, "text": "NP (nondeterministic polynomial-time) be-\ncause it can be solved in the aﬃrmative by a nondeterministic algorithm\n(guess an interpretation and check whether the formula is satisﬁed – if so,\nanswer “ye"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 26, "text": " al-\ngorithm for satisﬁability, there would exist one for any problem in NP (which\nwould imply that P = NP, which would be extremely surprising and disrup-\ntive).\nThe problem of deciding unsatisﬁabili"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 27, "text": "ays ran in polynomial time, that would mean that co-NP\n⊆NP. But that would imply that the complements of the problems in co-NP\nwere contained in the set of complements of problems in NP: that is, NP ⊆"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 28, "text": " ﬁrst achieved by Armin Haken in his\nPh.D. thesis of 1984 (University of Illinois at Urbana-Champaign). Haken\nessentially wrote down formulas that asserted that n + 1 ‘pigeons’ could ﬁt\nindividually i"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 29, "text": "ynomial time; the reverse is not possible.\n4except in a restricted form called “regular resolution.” Though he doesn’t cite himself,\nthe author of the textbook contributed to this research.\n12\n\nAlasda"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 30, "text": "ons that is ex-\nponential in n. Moreover, he showed that, in a standard axiomatic system\nfor propositional logic, the same sets of clauses had refutations of polynomial\nlength: the reason the examples"}, {"path": ".data\\docs\\ECE 208\\notes_ch4.pdf", "chunk_id": 31, "text": "m.\n• At each step, it produces a new clause, the resolvent of two clauses\nthat clash on a pair of literals.\n• It eventually yields the empty clause if and only if the original set of\nclauses is unsati"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 0, "text": "Chapter 5:\nBinary Decision Diagrams\n• A condensed representation of a truth table, in the form of a directed,\nacyclic graph.\n• The representation dates at least to the 1950s, but went through im-\nport"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 1, "text": "f a propositional formula. In the worst case, its size is exponential in the\nnumber of atoms in the formula. But often, it turns out that formulas of\ninterest have relatively small BDDs.\np\nq\nr\np ∨(q ∧"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 2, "text": " the edges are implicitly directed from above to below.\n• Once a leaf is reached, a full interpretation is determined, and the leaf\nis labelled with the corresponding truth value of the formula.\n• Sup"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 3, "text": "Q\nQ\nQ\nQ\n2\n\n– . . . and nodes whose children are one and the same can be elimi-\nnated:\nk\np\nk\nq\nk\nq\nk\nr\nF\nT\nQ\nQ\nQ\nQ\n@\n@\n@\n– These steps are repeated as many times as possible . . .\nk\np\nk\nq\nk\nr\nF\nT\nQ\nQ\nQ"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 4, "text": "s the string of\nvalues in the ﬁnal column of the truth table – or, the sequence of truth\nvalues that would label the respective leaves of the full binary decision\ntree:\n3\n\nk\np\nFFFTTTTT\nk\nq\nFFFT\nk\nq\nTT"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 5, "text": "erger of those leaves, and the deletion of\nall internal nodes between the root and those leaves:\nk\np\nFFFTTTTT\nk\nq\nFFFT\nF\nk\nr\nFT\nT\nlll\nlll\n• . . . and both of the leaves lying beneath the left-hand chi"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 6, "text": "oted at the\ntwo children would be identical, the children would therefore be merged, and\ntheir parent would be deleted:\n• If the two halves of such a string are diﬀerent, the string is called\na bead.1"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 7, "text": " its children – both labelled FT\n– would be identical.\n• the children are therefore merged, and their parent deleted;\n• and, in this case, the node resulting from the merger is then merged\nwith anothe"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 8, "text": " is not a bead.\n– Its children would have been two leaves labelled F;\n– those children would be merged and their parent deleted, so we\nhave simply linked the node labelled by q directly to a single le"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 9, "text": "eleted (and edges from their\nparents linked directly to the mergers of their children).\n• In particular, if the string of truth values associated with an internal\nnode is not a bead, then:\n– its child"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 10, "text": "BDD node as a distinct state.\n• The reduction of BDDs can be thought of as an instance of the reduc-\ntion that is used to reduce state machines.\n• As with state machines, the reduction of a BDD is can"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 11, "text": "ering of the set of all atoms occurring in two formulas.\n• Suppose that BDD representations of two formulas are given . . .\n• each obeying an ordering that is consistent with the overall ordering.\n• T"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 12, "text": ", and with the internal nodes numbered:\nk\np\n1\nk\nq\n2\nF\nk\nr\n3\nT\nlll\nlll\nk\nq\n1\nk\nr\n2\nF\nk\ns\n3\nT\nPPPPPPP\naaaaaaaa\nThese are both consistent with this ordering of the atoms: p, q, r, s.\nThink of the two BDD"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 13, "text": " state 1.\n• When the truth value of q is input, both machines respond, unless the\nleft-hand one is already in state T . . .\n• and so forth:\nk\np\n(1,1)\nk\nq\n(2,1)\nk\nq\n(T,1)\nk\nr\n(F, 2)\nF\n(F ∧F)\nk\nr\n(3,3)\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 14, "text": " means it\ntakes less advantage of the possibilities of performing operations directly on\nBDDs. The method described here is based on the operation called “meld-\ning” by\nImportance of the order of the "}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 15, "text": " leads to BDDs of exponential\nsize. Here are examples of ROBDDs based on the respective orderings, for\nthe case n = 3:\na1\nb1\na2\nb2\na3\nb3\nT\nF\na1\na2\na3\na3\na2\na3\nb1\nb1\na3\nb1\nb1\nb2\nb2\nb3\nT\nF\n10\n\nNote that"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 16, "text": "ion can give a general idea of their utility. BDDs\ncan be used to represent the state-transition relation of a digital system\n‘symbolically,’ rather than explicitly, such as in the form of a state mac"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 17, "text": "hese formulas can be represented as a BDD, and the overall state-\ntransition relation of the counter represented as their conjunction. Indeed,\nif we replace T with 1, and F with 0, the resulting BDD r"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 18, "text": "xn for the case where\nn = 6, showing that the formulas can be represented as BDDs of linear size,\nwhereas the state-transition diagram for the counter contains 2n states:\n11\n\nx1\nx2\nx3\nx4\nx5\nx6\nx6\nT\nF\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch5.pdf", "chunk_id": 19, "text": "e to perform formal veriﬁcation of large, industrial\nsystems . . .\n• but, in the current state of the art, methods based on ‘SAT solvers’ are\nmore powerful. SAT solvers are the topic of the next chapt"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 0, "text": "Chapter 6:\nPropositional Logic: SAT solvers\nBoolean satisﬁability, or SAT for short, is the decision problem of determining\nwhether a given propositional-logic formula (represented as a set of clauses"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 1, "text": " has 2n rows, where n\nis the number of atomic propositions in a formula. Thus, any deterministic\nalgorithm for satisﬁability based on an exhaustive check of the truth table\nruns in exponential – not p"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 2, "text": "ndeterministic algorithm is considered to ‘solve’ SAT, and to do so in poly-\nnomial time. That means that SAT belongs to the class NP. This class can\nbe thought of consisting of those problems for whi"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 3, "text": "olved SAT in polynomial\ntime, the same would be true of all problems in NP.\nWhen a problem belongs to NP and is NP-hard, it is called NP-complete.\nDespite decades of eﬀort, no one has ever been able t"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 4, "text": "rse inclusion holds.\nA particularly great amount of eﬀort has been directed toward solving\nSAT as eﬃciently as possible; and because SAT is NP-hard, any problem in\nNP can be reduced to SAT in determin"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 5, "text": "T solvers are currently a tool of choice for the formal\nveriﬁcation of large computing systems, and are the basis of many artiﬁcial-\nintelligence systems. This chapter gives a brief introduction the t"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 6, "text": "m is essentially a method of searching for a satisfying\npartial interpretation of a set of clauses.\nDeﬁnition 6.18 Let S be a set of clauses and let I be a partial interpre-\ntation for S. For any clau"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 7, "text": "\nthat assigns T to q and F to r. Then Iqr satisﬁes the ﬁrst three clauses in\nS, but the fourth, r, is a conﬂict clause for Iqr.\n□\nIn addition to search, unit resolution will be performed to infer nece"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 8, "text": " referred to as unit\npropagation, or as Boolean constraint propagation.\n2\n\nAlgorithm 6.20: (DPLL algorithm)\nInput: A formula A in clausal form.\nOutput: A report that A is unsatisﬁable, or a report tha"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 9, "text": "as much as possible. Construct I ′ by adding to I all\nthe assignments made during unit resolution.\nCheck satisfaction: Evaluate B′ under the partial interpretation I ′:\n• if B′ contains a conﬂict clau"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 10, "text": "pretation I ′, together with the\nassignment of the complement of val to p.\n• result ←DPLL(B′, I2).\n• return result.\nNote: when DPLL calls itself, the set of clauses B′ should be understood\nas having b"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 11, "text": "discuss ways of improving\nthe DPLL algorithm:\npq, qr, pst, psu, ptu, psu, psu .\nIf this is A, then the recursive procedure DPLL will initially be called with\nthis set of clauses and the empty partial "}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 12, "text": "tu, psu, psu\np 7→T :\nqr, st, su, tu, su, su\nq 7→T :\nst, su, tu, su, su\ns 7→T :\nt, tu, u\ns 7→F :\nu, tu, u\nq 7→F :\nr, st, su, tu, su, su\ns 7→T :\nt, tu, u\ns 7→F :\nu, tu, u\np 7→F :\nq, qr\nreturn p 7→F, q 7"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 13, "text": "cular:\n• the encoding of a constraint-satisfaction problem as an instance of SAT;\n• the extent to which the number of clauses may drop as truth values are\nassigned to atoms.\n4\n\n6.5 Improving the DPLL "}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 14, "text": "alue F. But if l has the value T, any clause containing l can be\ndeleted.\nSuch a literal is called a pure literal (in the context of the given set of\nclauses), and the deletion of clauses that contain"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 15, "text": "erpretation, the DPLL algorithm always backtracks to the nearest ancestor\nin the search tree at which an atom was chosen to “branch on,” and only one\nof its possible truth values has so far been consi"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 16, "text": "retation that assigns F to p and T to q. But\nsuppose that the truth value of p is set to T; then, in the next call to DPLL,\nwhen B′ is evaluated with respect to the corresponding partial interpretatio"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 17, "text": "isﬁable. But the DPLL algorithm will not recognize that fact, and\nmay choose to branch on q and r, in which case it will end up backtracking\nand eﬀectively determining multiple times that the subset o"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 18, "text": "r backtracking; the number in parentheses indicates\nthe decision level at which that assignment occurred. (The decision level\ncorresponds to the level of indentation used in our earlier description of"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 19, "text": "at decision level 1, and the assignment of T to s two\n6\n\nbranching steps later, at decision level 3; and that intervening branching on\nq or r (at level 2) does not enter into the conﬂict.\nIn order to "}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 20, "text": "rack to the latest\ndecision level (3), and assign the value F to s. That assignment results in a\nnew implication graph:\np (1)\n¬s (3)\nu\n¬u\nκ (conﬂict)\npsu\npsu\npsu\npsu\nHere again, a conﬂict arises. At t"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 21, "text": " of F to s, and ensures the existence of the conﬂict. On the basis\nof the implication graph, a SAT solver can therefore add the further learned\nclause ¬(p∧¬s) ≡(¬p∨s) ≡ps to the set of clauses, and al"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 22, "text": " quickly results in the empty set\nof clauses, showing the original set to be satisﬁable.\nSAT solvers that incorporate clause learning and non-chronological back-\ntracking are called Conﬂict-Driven Cla"}, {"path": ".data\\docs\\ECE 208\\notes_ch6.pdf", "chunk_id": 23, "text": "n curtail long searches, at the cost of no longer being guaran-\nteed to ﬁnd a solution.\nFree SAT solvers\nFree, open-source SAT solvers include MiniSat and MicroSat – the latter\nconsisting of less than"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 0, "text": "Chapter 7:\nPredicate Logic: Syntax, Semantics,\nUndecidability\nThis chapter summarizes parts of chapters 7, 8, and 9 of the textbook, and\ntouches upon the subject of chapter 12.\nMany applications requi"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 1, "text": "ables. Logics equipped with such features are referred to as predicate logic,\nor alternatively as ﬁrst-order logic (so-called “higher-order logics,” such as\nsecond-order logic, allow quantiﬁcation not"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 2, "text": "T solvers, in addition to propositional resolution, we ﬁrst brieﬂy discuss\nan important price that is paid for the expressivity of predicate logic: the\nfailure of decidability.\nUndecidability of predi"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 3, "text": "d an important\nrole in organizing mathematical research throughout the twentieth century,\ndespite being shown early in the decades to be doomed to failure.\nOne reason, among others, is that satisﬁabil"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 4, "text": "s results speciﬁcally identify fundamental limitations of formal\nveriﬁcation of computer systems: they relate to the problem of deciding\nwhether an algorithm will terminate when run on a given input. "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 5, "text": "t. Consider therefore the\nproblem of deciding whether a given program P terminates – or halts – in\nthe reﬂexive scenario where its input is P itself.\nTuring’s proof proceeds by contradiction. Suppose "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 6, "text": " could be made to go into\nan inﬁnite loop, and never terminate; otherwise, it could simply terminate\nnormally.\nCall the modiﬁed program P ∗∗. What would happen if this program were\nrun on its own inpu"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 7, "text": " arbitrary program halts on its own input. The ‘halting problem,’ however\nartiﬁcial, is therefore an example of a problem that is undecidable.\nThe halting problem therefore proves the existence of pro"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 8, "text": "P. Call the modiﬁed version\nP ′; then P ′ halts on the empty input if and only if P halts on its own input.\nThis means that the ﬁrst version of the halting problem ‘reduces’ to that\n2\n\nof deciding whe"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 9, "text": "ion problem to which an undecidable problem\nreduces must itself be undecidable.\nSuch is the case for satisﬁability of\npredicate-logic formulas. Given an arbitrary program P, one can write down\na predi"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 10, "text": " can express the\nhalting of an arbitrary program on, say, the empty input, and the satisﬁabil-\nity of an arbitrary formula is therefore undecidable.\nThere does exist a version of resolution for predic"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 11, "text": "l methods of mathematical reasoning. Despite the discovery\nthat such formal methods have important limitations – particularly when\napplied to the analysis of algorithms – predicate logic remains the f"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 12, "text": ". If n = 1, the predicate symbol\nis unary; if n = 2, it is binary; in general, it is n-ary. The arity will usually\nnot be indicated explicitly; it will be clear from the number of arguments\nemployed.\n"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 13, "text": "redicate symbol followed\nby a list of n arguments in parentheses: p(t1, t2, . . . , tn), where each ti is\neither a constant symbol or a variable. More generally, a well-formed formula\n(wﬀ), or simply,"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 14, "text": " children that\nare formulas is a formula;\n• the set of all ﬁrst-order formulas is the smallest set that satisﬁes the\nabove conditions.\nThe concept of structural induction carries over straightforwardl"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 15, "text": " The scope of variables\nDeﬁnition 7.11 The scope of the quantiﬁer ∀x in the quantiﬁed formula\n∀x A is the formula A. It is not necessary for x actually to occur within A.\n• In the above example, the s"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 16, "text": "thin the scope of a quantiﬁer ∀x or ∃x.\nAn occurrence that does lie within the scope of such a quantiﬁer is a bound\noccurrence. A variable may have both free and bound occurrences within\nthe same form"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 17, "text": "at some of the variables x1, . . . , xn\nare free variables in the formula A, but this will not mean that those are\nthe only free variables in A.\nWe use the notation so that we can write\nA(t1, . . . , "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 18, "text": "ng that xj can be substituted for all free occurrences of xj without\ncreating any new bound occurrences of xj).\nExample 7.13 The formula p(x, y) has two free variables, and ∃yp(x, y) has\none free vari"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 19, "text": "ext section\nthat a bound occurrence of a variable is a “dummy” variable: the variable\ncan be changed to another letter without aﬀecting the interpretation of the\nformula. Thus, the above universal clo"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 20, "text": " is\nan ni-ary relation on D that is assigned to the predicate symbol pi, and an\nelement di ∈D is assigned to the constant symbol ai.\nThere exist logics with multiple domains – or ‘types.’ These are co"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 21, "text": " an interpretation for a formula A. An assign-\nment σIA : V −→D is a function that maps every free variable v ∈V to an\nelement d of the domain D of the interpretation IA.\nThe map σIA[x ←d] is an assig"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 22, "text": "e determines the truth\nvalues of atomic formulas. That in turn determines the truth value of the\nformula as a whole, through the truth tables for the Boolean operators.\nFor example, consider the formu"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 23, "text": " mean that 2 ≤3 and 3 ≤4 implies 2 ≤4, which happens\nto be true.\nNow suppose that we wish to consider a formula that contains variables,\nbut no quantiﬁers. Then the assignment σI plays a similar role "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 24, "text": "d y? That is where the assignment comes in. Consider the assignment\nσI that maps x to 4 and y to 3. Under I and σI , the formula means the\nsame thing as in the previous example.\n7\n\nBut of course, we w"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 25, "text": "ables unchanged. The formula ∀x A should have the truth value T\nunder an interpretation I and an assignment σI , if and only if, whenever\nwe reassign to x any domain element d, the formula A has the t"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 26, "text": "he speciﬁc value assigned to x by the\nassignment σI , but all possible values that could be assigned to that variable,\nand determine whether all of those possible values lead to the satisfaction\nof th"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 27, "text": " and only if A has the truth value\nT under I and σI [x ←d], for all d ∈D.\nIn other words, ∀x A is assigned the truth value T under interpretation\nI and assignment σI if and only if, when the assignmen"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 28, "text": "ue of A under IA and σIA, is\ndeﬁned recursively as follows (with vσIA replaced by vσ):\n• Let A = pk(c1, . . . , cn) be an atomic formula, where each ci is either a\nconstant symbol or a variable. Then "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 29, "text": " vσ(∃xA1) = T iﬀvσ[x←d](A1) = T for some d ∈D.\n9\n\nTheorem 7.20 Let A be a closed formula, IA be an interpretation for A\nand σIA an assignment. Then vσIA(A) does not depend on the assignment\nσIA.\nBy th"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 30, "text": "m 7.22 Let A be a formula with free variables x1, . . . , xn, and let\nIA be an interpretation for A. Then:\n1. vσIA(A) = T for some assignment σIA iﬀvI (∃x1 . . . ∃xnA) = T; and\n2. vσIA(A) = T for all "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 31, "text": " ⊨A.\n• A is unsatisﬁable if it is not satisﬁable.\n• A is falsiﬁable if it is not valid.\nNote: this deﬁnition diﬀers from that in the text, mainly because it applies to\nall formulas, whether closed or "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 32, "text": " such\nthat vI (∀x p(x)) = T and vI (p(a)) = F. But, by deﬁnition, the former\nimplies that vσI [x←d](p(x)) = T, and that holds if and only if d ∈R, which\nmeans vI (p(a)) = T, a contradiction.\n□\nExample"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 33, "text": " I =\n(N, {>}, ∅}; there is no natural number less than zero.\n• ∃x∃y (p(x) ∧¬p(y)).\nThis formula can only be true in interpretations over domains with at\nleast two elements.\n• ∀x p(a, x).\nThis formula "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 34, "text": "x) =⇒q(x)) =⇒(∀x p(x) =⇒∀x q(x)).\nThis formula is also valid, but its converse is not.\n□\n12\n\n7.3.3 An interpretation for a set of formulas\nThis notion extends straightforwardly from propositional to p"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 35, "text": "in the set.\n7.4 Logical equivalence and logical consequence\nThe formulas A1 and A2 are logically equivalent if any interpretation I for\nthe set {A1, A2} of the two formulas is a model for A1 iﬀit is a"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 36, "text": " error. Find it. [The error\ndoes not make the result wrong, but it does make it weaker than necessary.]\n13\n\n8.2 Hilbert system H\nThe axioms of H are:\nAxiom 1 ⊢(A ⇒(B ⇒A)) ,\nAxiom 2 ⊢(A ⇒(B ⇒C)) ⇒((A ⇒"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 37, "text": "on (Gen):\n⊢A ⇒B\n⊢A\n⊢B\n,\n⊢A\n⊢∀x A\n.\nIt can readily be checked that all of the axioms are valid formulas. More-\nover, if the premises of an inference rule are valid, then so is its conclusion.\nNote: Axi"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 38, "text": "¬∀x ¬A. Such treatment\nis justiﬁed by the formal semantics.\n14\n\nGeneralization and specialization\nThe new inference rule, generalization, formalizes a common inference: if A\ncan be shown to hold for a"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 39, "text": "eneralization rule (Gen) may have been used in\nthe deduction.\nBecause our semantics treats formulas with free variables as if those vari-\nables were universally quantiﬁed, the inference\n⊢A\n⊢∀x A\nis so"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 40, "text": "nce, at\nleast one of which depends on A.\nRule 8.9 (Deduction Rule)\nSuppose that there exists a deduction of B from U ∪{A} in which no\napplication of Gen to a formula that depends on A has as its quant"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 41, "text": "y: Suppose that there exists a deduction of\nB from U ∪{A} in which no application of Gen has as its quantiﬁed variable\na variable that occurs free in A. Then U ⊢A ⇒B.\n□\nDeduction Rule, 2nd Corollary: "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 42, "text": "r database applications, we shall now bring in functions, for\ngreater expressivity.\nDeﬁnition 9.1 Let F be a countable set of function symbols, each with an\narity of at least one. Then terms are deﬁne"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 43, "text": "ms are\na, x, f(a, x), f(g(x), y), g(f(a, g(b)))) ;\nand examples of atomic formulas are\np(a, b), p(x, f(a, x)), q(f(a, a), f(g(x), g(x))) .\n□\nThe deﬁnitions of free and bound occurrences of variables, "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 44, "text": "ﬁnition of an interpretation:\nDeﬁnition 9.3 Let A be a formula and suppose that the predicate symbols\noccurring in A are p1, . . . , pk, the functions symbols in A are f n1\n1 , . . . , f nl\nl\nand the "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 45, "text": "nt of an element dn ∈D to\neach constant symbol an.\nThe rest of the deﬁnitions of semantics are unchanged, except that of\nthe truth value of an atomic formula under an interpretation IA and an\nassignme"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 46, "text": "the function to which the nj-ary function symbol fj is\nassigned by the interpretation.\nNow, the truth value assigned to an atomic formula A = pi(t1, . . . , tni)\nis deﬁned so that\n• vσIA(A) = T iﬀ(σIA"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 47, "text": "rst-order logic with functions. So can the statement and the\nproof of the Deduction Rule.\n8.4 Proofs of Theorems in H\nThe proof system H for ﬁrst-order logic subsumes that for propositional\nlogic: all"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 48, "text": "(x)\nContrapositive Rule 1\n3. ⊢A(t) ⇒∃x A(x)\nDouble Negation Rule 2\n□\nTheorem 8.15\n⊢∀x A(x) ⇒∃x A(x) .\nProof: By deﬁnition, x is a term that is free for x in A(x).\n1. ⊢∀x A(x) ⇒A(x)\nAxiom 4\n2. ⊢A(x) ⇒∃"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 49, "text": "A(x)} ⊢B(x)\nMP 3, 6\n8.{∀x (A(x) ⇒B(x)), ∀x A(x)} ⊢∀x B(x)\nGen 7\n9.{∀x (A(x) ⇒B(x))} ⊢∀x A(x) ⇒∀x B(x)\nDeduction, 1st Cor. 8\n10. ⊢∀x (A(x) ⇒B(x)) ⇒(∀x A(x) ⇒∀x B(x))\nDeduction, 1st Cor. 9\n□\n19\n\n[Rule 8"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 50, "text": "))\nGen 2\n4. ⊢∀x (¬A(x, y) ⇒¬∀y A(x, y))\n=⇒(∀x ¬A(x, y) ⇒∀x ¬∀y A(x, y))\nTheorem 8.16\n5. ⊢∀x ¬A(x, y) ⇒∀x ¬∀y A(x, y)\nMP 3, 4\n6. ⊢∃x ∀y A(x, y) ⇒∃x A(x, y)\nContrapositive 5\n7. ⊢∀y [∃x ∀y A(x, y) ⇒∃x A("}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 51, "text": " second theorem:\n1. {¬(A ⇒∃x B(x)} ⊢A ∧∀x ¬B(x)\nAbbreviation\n2. {¬(A ⇒∃x B(x)} ⊢A ∧¬B(x)\nSpecialization 1\n3. {¬(A ⇒∃x B(x)} ⊢∀x (A ∧¬B(x))\nGen 2\n4. {¬(A ⇒∃x B(x)} ⊢∀x ¬(A ⇒B(x))\nAbbreviation 3\n5. {¬(A"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 52, "text": " 3\n5. ⊢∀x ¬(A ⇒B(x)) ⇒A ∧∀x ¬B(x)\nDeduction, 1st Cor. 4\n6. ⊢(A ⇒∃x B(x)) ⇒∃x (A ⇒B(x))\nContrapositive 5\n□\nTheorem 8.20\n⊢∀x A(x) ⇐⇒∀y A(y) .\nProof: See the textbook.\n□\nTheorem 8.21 Let B be a formula t"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 53, "text": "ny set U of formulas, and a closed formula A, we shall again say that a\ndeductive system satisﬁes strong soundness if\nU ⊢A implies U ⊨A\n– in other words, if every formula A that can be deduced from U "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 54, "text": " conclusion. Strong soundness of H follows.\nA proof of strong completeness is similar to that for the propositional\nHilbert system (see the solutions of assignment 2). As in the propositional\ncase, a "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 55, "text": "tion, with\nnothing to go on but the syntactic property that the set is consistent. Deﬁne\na ground term to be a term that contains no variables. A suitable domain\nconsists of all ground terms of the se"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 56, "text": "is true, then so is B(t); the ground term\nt denotes a speciﬁc domain element that satisﬁes the existentially quantiﬁed\nformula. Indeed, in our case, the ground term will actually be such a domain\nelem"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 57, "text": " B3(xi3), . . . be an enumeration of all\nformulas with only a single free variable.\nDeﬁne the nondecreasing sequence of sets of formulas\nU0 ⊆U1 ⊆U2 ⊆. . .\nas follows:\nU0 := U ,\nUj := Uj−1 ∪{∃x Bj(xij)"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 58, "text": "j is not. Then, because any formula can be deduced\nfrom an inconsistent set,\nUj ⊢¬(∃x Bj(xij) ⇒Bj(cj))\niﬀUj−1 ∪{∃x Bj(xij) ⇒Bj(cj)} ⊢¬(∃x Bj(xij) ⇒Bj(cj))\niﬀUj−1 ⊢(∃x Bj(xij) ⇒Bj(cj)) ⇒¬(∃x Bj(xij) ⇒B"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 59, "text": "t is, Uj−1 ⊢¬∃y Bj(y). By\nTheorem 8.20, this contradicts the consistency of Uj−1. Therefore, U ′ ⊇U\nis consistent. Moreover, by construction, it contains witnesses.\n□\nA set U of formulas is negation-c"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 60, "text": "tnesses. Then U has a model whose domain is the set of\nground terms of U.\nProof: Let each constant symbol be assigned to itself, and any function sym-\nbol f\nnj\nj\nto the function that maps any nj-tuple"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 61, "text": " Elliott Mendelson, Introduction to Mathematical Logic, Chap-\nman and Hall, 4th edition.\n□\nSay that an interpretation is a countable model of a set of formulas if it\nis a model of the set and its doma"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 62, "text": "t of a set that\nalready contained witnesses), and by the proof of Lindenbaum’s Lemma, it\ntoo will contain a countable set of closed terms. The Model-Existence Lemma\nthen implies the existence of a cou"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 63, "text": " the\npreceding theorem, U∪{¬A} has a countable model. That contradicts U ⊨A,\nso we must in fact have U ⊢A.\n□\nThe completeness of H was ﬁrst proved by G¨odel; strong completeness\nwas then proved by Hen"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 64, "text": "rogram is the undecidability discussed at the beginning of\nthis chapter. We’ll conclude with another impediment discovered by G¨odel.\nThough G¨odel proved the completeness of ﬁrst-order logic, he also"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 65, "text": "ormula A can be deduced from a set of assumptions U if and only if it is\na logical consequence of U – every model of U is a model of A.\nBut G¨odel showed that mathematical logic is nevertheless ‘incom"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 66, "text": "all such formulas is countable,\nbut that their enumeration can be carried out eﬀectively; a general term for\nthis property is recursively enumerable, and a theory whose theorems are\nrecursively enumer"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 67, "text": "other way of saying the same thing is that the set of theorems\nwould be not just recursively enumerable, but recursive. Equivalently, by\nstrong soundness and strong completeness, the set of logical co"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 68, "text": "hat supports suﬃcient number-theoretic concepts1 also\nallows for reasoning about the formulas of the logic itself, and even about\nthe deductive system. In particular, G¨odel showed that such a logic a"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 69, "text": " standard interpretation\nis a model for the U, G¨odel’s self-referential formula cannot be a theorem,\nby strong soundness. But then its negation cannot be a theorem either, for\nG¨odel’s formula is tru"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 70, "text": "that hold in some models of U but not in others. The ‘standard’\nmodel is not the only model.\nNeither do these results contradict Lindenbaum’s Lemma, which shows\nthat U can be extended to a consistent "}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 71, "text": "s recursively enumerable, then that set would in fact be\ndecidable: if an algorithm listed the theorems, then eventually either A or\nits negation would appear, determining whether or not A was provabl"}, {"path": ".data\\docs\\ECE 208\\notes_ch7,8.pdf", "chunk_id": 72, "text": "identiﬁed, such\nformal reasoning still forms the theoretical foundation of mathematics; and\nit continues to grow in importance as a means of design and analysis of\ncomputing systems.\n27"}]