# agent/orchestrator.py
import asyncio
import re
import json
import ast
from typing import List, Dict, Any

from agent.memory import Memory
from agent.retriever import Retriever
from agent.llm import LLM
from agent.config import APP, CHUNK, LLMConfig  # è¯»å– chunker é…ç½®
from agent.chunkers import get_chunker  # æœ¬åœ°åˆ‡å‰²å·¥å‚

QA_PROMPT = """ä½ æ˜¯å­¦ä¹ åŠ©æ•™ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚
- åªåŸºäºæä¾›çš„[RAG]ç‰‡æ®µã€‚
- è‹¥ç‰‡æ®µä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´â€œä¸è¶³â€ã€‚"""

EXPLAIN_PROMPT = """ä½ æ˜¯å­¦ä¹ åŠ©æ•™ï¼Œç”¨ä¸­æ–‡è®²è§£çŸ¥è¯†ç‚¹ã€‚
- åŸºäº[RAG]ç‰‡æ®µã€‚
- ç»™å‡ºï¼šç›´ç™½è§£é‡Šã€å…³é”®å…¬å¼/å®šä¹‰ã€ç±»æ¯”ä¸¾ä¾‹ã€å¸¸è§è¯¯åŒºã€‚"""

SOLVE_PROMPT = """ä½ æ˜¯å­¦ä¹ åŠ©æ•™ï¼Œç”¨ä¸­æ–‡è§£ç­”ä¹ é¢˜ã€‚
- å…ˆå†™æ€è·¯ï¼Œå†åˆ†æ­¥éª¤æ¨å¯¼ï¼Œæœ€åç»™å‡ºç­”æ¡ˆã€‚
- è‹¥[RAG]ç‰‡æ®µä¸è¶³ï¼Œå¯ç”¨å¸¸è¯†æˆ–æ•°å­¦çŸ¥è¯†è¡¥å……ï¼Œä½†è¦æ ‡æ˜ã€‚"""


def build_messages(mem: Memory, rag_ctx: list[dict] | None, tool_obs: str | None, mode: str):
    if mode == "qa":
        sys_prompt = QA_PROMPT
    elif mode == "explain":
        sys_prompt = EXPLAIN_PROMPT
    elif mode == "solve":
        sys_prompt = SOLVE_PROMPT
    else:
        sys_prompt = QA_PROMPT

    msgs = [{"role": "system", "content": sys_prompt}]

    if rag_ctx:
        ctx = "\n".join(
            [
                f"({i+1}) æ¥è‡ª: {meta.get('source')}#{meta.get('chunk_id')}\n{meta['text']}"
                for i, meta in enumerate(rag_ctx)
            ]
        )
        msgs.append({"role": "system", "content": "[RAG]\n" + ctx})

    if tool_obs:
        msgs.append({"role": "system", "content": f"[Tool Result]\n{tool_obs}"})

    msgs.extend(mem.context())
    return msgs


async def _tools_call(router, name: str, args: dict):
    if router is None:
        raise RuntimeError("å·¥å…·ä¸å¯ç”¨ï¼šæœªè¿æ¥ MCPã€‚")
    if hasattr(router, "call"):
        return await router.call(name, args)
    if hasattr(router, "invoke"):
        return await router.invoke(name, args)
    if getattr(router, "mcp", None) and hasattr(router.mcp, "tools_call"):
        return await router.mcp.tools_call(name, args)
    raise RuntimeError("æ— æ³•è°ƒç”¨å·¥å…·ï¼šæœªå‘ç°å¯ç”¨çš„è°ƒç”¨æ–¹æ³•ã€‚")


def _parse_matrix_side(text: str):
    text = text.strip()
    try:
        return json.loads(text)
    except Exception:
        return ast.literal_eval(text)


def _strip_code_block(code: str) -> str:
    code = code.strip()
    if code.startswith("```") and code.endswith("```") and len(code) >= 6:
        return code[3:-3]
    return code


async def _run_mode_dispatch(router, payload: str):
    """
    è§£æå¹¶æ‰§è¡Œ run æ¨¡å¼ï¼š
      è¯­æ³•ï¼š<lang> <code or ```...```> [--timeout=ç§’] [--verbose]
      è¯­è¨€ï¼špython/py, c, cpp/c++/cc, java
    é»˜è®¤è¾“å‡ºå°½é‡ç²¾ç®€ï¼›åŠ  --verbose è¾“å‡ºå®Œæ•´ç»†èŠ‚ã€‚
    """
    import re

    # æå–å¯é€‰ verbose / timeout
    verbose = False
    if "--verbose" in payload or "-v" in payload.split():
        verbose = True
        payload = payload.replace("--verbose", "").replace("-v", "")

    timeout = None
    m_to = re.search(r"--timeout\s*=\s*([0-9]+(?:\.[0-9]+)?)", payload)
    if m_to:
        try:
            timeout = float(m_to.group(1))
        except Exception:
            pass
        payload = payload[:m_to.start()] + payload[m_to.end():]

    payload = payload.strip()
    if not payload:
        return "ç”¨æ³•ï¼š/run <python|c|cpp|java> <code or ```...```> [--timeout=ç§’] [--verbose]"

    parts = payload.split(None, 1)
    lang = parts[0].lower()
    code = parts[1].strip() if len(parts) > 1 else ""

    if lang in ("python", "py"):
        tool = "python.run_code"
    elif lang == "c":
        tool = "c.run_code"
    elif lang in ("cpp", "c++", "cc"):
        tool = "cpp.run_code"
    elif lang == "java":
        tool = "java.run_code"
    else:
        return "ä¸æ”¯æŒçš„è¯­è¨€ï¼Œè¯·ä½¿ç”¨ï¼špython/pyã€cã€cppã€javaã€‚"

    if not code:
        return "è¯·åœ¨åŒä¸€è¡Œæä¾›ä»£ç ï¼Œæˆ–åœ¨åŒä¸€æ¡è¾“å…¥ä¸­ç”¨ä¸‰å¼•å·åŒ…è£¹ï¼š```...```"

    # å»é™¤åŒä¸€æ¡è¾“å…¥å†…é—­åˆçš„ä¸‰å¼•å·
    def _strip_code_block(s: str) -> str:
        s = s.strip()
        if s.startswith("```") and s.endswith("```") and len(s) >= 6:
            return s[3:-3]
        return s

    code = _strip_code_block(code)
    code = code.replace("\\n", "\n").replace("\\t", "\t")

    args = {"code": code}
    if timeout is not None:
        args["timeout"] = timeout

    res = await _tools_call(router, tool, args)

    # ---------- ç²¾ç®€/è¯¦ç»† ä¸¤ç§æ ¼å¼ ----------
    def _indent(text: str, pad: str = "    ") -> str:
        if text is None:
            text = ""
        if not text.endswith("\n"):
            text += "\n"
        return "".join(pad + ln for ln in text.splitlines(True))

    def fmt_section(title, obj):
        if not obj:
            return ""
        return (
            f"{title}:\n"
            f"  exit_code: {obj.get('exit_code')}\n"
            f"  time_ms:   {obj.get('time_ms')}\n"
            f"  stdout:\n{_indent(obj.get('stdout',''))}\n"
            f"  stderr:\n{_indent(obj.get('stderr',''))}\n"
        )

    if verbose:
        # è¯¦ç»†æ¨¡å¼ï¼šä¿ç•™å®Œæ•´ç»“æ„ä¿¡æ¯
        if tool == "python.run_code":
            out = [
                f"ğŸŸ© {tool}",
                f"workdir: {res.get('workdir','')}",
                f"files:   {', '.join(res.get('files', []))}",
                fmt_section("run", res),
            ]
        else:
            out = [
                f"ğŸŸ© {tool}",
                f"workdir: {res.get('workdir','')}",
                f"files:   {', '.join(res.get('files', []))}",
                fmt_section("compile", res.get("compile")),
            ]
            if res.get("compile", {}).get("exit_code") == 0:
                out.append(fmt_section("run", res.get("run")))
        return "\n".join(s for s in out if s)

    # ç²¾ç®€æ¨¡å¼ï¼šåªç»™æœ€å…³å¿ƒçš„ç»“æœ
    if tool == "python.run_code":
        rc = res.get("exit_code", 0)
        if rc == 0:
            return res.get("stdout", "").rstrip("\n") or "(æ— è¾“å‡º)"
        else:
            # å¤±è´¥ï¼šç»™æœ€å…³é”®çš„é”™è¯¯ï¼ˆstderr çš„ç¬¬ä¸€æ®µï¼‰
            err = (res.get("stderr") or "").strip()
            return f"è¿è¡Œå¤±è´¥ (exit={rc}): {err.splitlines()[0] if err else 'unknown error'}"
    else:
        comp = res.get("compile", {}) or {}
        if comp.get("exit_code", 0) != 0:
            err = (comp.get("stderr") or "").strip()
            return f"ç¼–è¯‘å¤±è´¥ (exit={comp.get('exit_code')}): {err.splitlines()[0] if err else 'unknown error'}"
        run = res.get("run", {}) or {}
        rc = run.get("exit_code", 0)
        if rc == 0:
            return run.get("stdout", "").rstrip("\n") or "(æ— è¾“å‡º)"
        else:
            err = (run.get("stderr") or "").strip()
            return f"è¿è¡Œå¤±è´¥ (exit={rc}): {err.splitlines()[0] if err else 'unknown error'}"


class Orchestrator:
    def __init__(self, llm: LLM, retriever: Retriever, memory: Memory, router, rag_top_k=4):
        self.llm = llm
        self.retriever = retriever
        self.memory = memory
        self.router = router
        self.rag_top_k = rag_top_k

        # é¢„å…ˆæ„é€  chunkerï¼ˆä»… llm_outline éœ€è¦ llmï¼‰
        self._chunker = get_chunker(
            name=CHUNK.name,
            chunk_size=CHUNK.chunk_size,
            chunk_overlap=CHUNK.chunk_overlap,
            semantic_model=CHUNK.semantic_model,
            sim_threshold=CHUNK.semantic_sim_threshold,
            llm=self.llm,
            max_chars_per_call=CHUNK.max_chars_per_call,
        )

    async def _mcp_read_dir(self, docs_dir: str) -> List[Dict[str, Any]]:
        """åªé€šè¿‡ MCP è¯»å–æ–‡ä»¶ï¼ˆfile.read_dirï¼‰ã€‚"""
        if not self.router:
            return []
        args = {
            "dir": docs_dir,
            "patterns": ["*.pdf", "*.txt", "*.md", "*.docx"],
            "recursive": True,
            "limit": None,
            "normalize": True,
        }
        try:
            res = await _tools_call(self.router, "file.read_dir", args)
            return res.get("files", []) if isinstance(res, dict) else []
        except Exception:
            # MCP ä¸å¯ç”¨æˆ–å¤±è´¥å°±è¿”å›ç©ºï¼Œå¤–é¢ä¼šåšæœ¬åœ°å…œåº•
            return []

    async def reindex(self) -> dict:
        """
        é‡æ–°æ„å»ºç´¢å¼•ï¼š
          1) ç”¨ MCP è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹ï¼ˆä»… read_dirï¼‰
          2) ç”¨æœ¬åœ° chunker åˆ‡å‰²ï¼ˆå¯èµ° LLM å¤§çº²ï¼‰
          3) å†™å…¥ retrieverï¼ˆå¸¦ built_by å’Œ docs_sigï¼‰
        """
        print("å¼ºåˆ¶é‡å»ºç´¢å¼•ä¸­...")

        # 1) è¯»å–æ–‡ä»¶ï¼ˆä¼˜å…ˆ MCPï¼‰
        files = await self._mcp_read_dir(str(APP.rag.docs_dir))
        used_mcp = bool(files)

        # 2) æœ¬åœ°å…œåº•è¯»å–ï¼ˆè‹¥ MCP ä¸å¯ç”¨ï¼‰
        if not files:
            from pathlib import Path
            print("â¡ï¸ ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è¯»å– fallback")
            base = Path(APP.rag.docs_dir)
            for p in base.rglob("*"):
                if p.is_file() and p.suffix.lower() in (".pdf", ".txt", ".md", ".docx"):
                    try:
                        content = p.read_text("utf-8", errors="ignore")
                    except Exception:
                        content = ""
                    try:
                        st = p.stat()
                        mtime = int(st.st_mtime)
                        size = int(st.st_size)
                    except Exception:
                        mtime = 0
                        size = len(content)
                    files.append({
                        "meta": {"source": str(p), "mtime": mtime, "size": size},
                        "content": content
                    })

        # 2.5) è®¡ç®— docs ç­¾åï¼ˆç»Ÿä¸€ï¼šæŒ‰ source/mtime/sizeï¼‰
        import hashlib
        sig_items = []
        for f in files:
            meta = f.get("meta") or {}
            src = str(meta.get("source") or meta.get("path") or "unknown")
            mtime = int(meta.get("mtime", 0)) if isinstance(meta.get("mtime", 0), (int, float)) else 0
            size_meta = int(meta.get("size", 0)) if isinstance(meta.get("size", 0), (int, float)) else 0
            content = f.get("content") or ""
            size_for_sig = size_meta if size_meta > 0 else len(content)
            sig_items.append((src, mtime, int(size_for_sig)))
        h = hashlib.sha256()
        for k, m, s in sorted(sig_items, key=lambda x: x[0]):
            h.update(str(k).encode());
            h.update(b"|")
            h.update(str(int(m)).encode());
            h.update(b"|")
            h.update(str(int(s)).encode());
            h.update(b"\n")
        docs_sig = h.hexdigest()

        # 3) æœ¬åœ°åˆ‡å‰²ï¼ˆæ›¿ä»£ MCP file.chunkï¼‰ï¼Œchunker åç§°æ¥è‡ª config
        texts, metadatas = [], []
        total_chunks = 0
        for f in files:
            text = (f.get("content") or "").strip()
            if not text:
                continue
            meta = f.get("meta") or {}
            chunks = self._chunker.split(text)
            total_chunks += len(chunks)
            texts.extend(chunks)
            metadatas.extend([meta | {"chunk_id": i} for i in range(len(chunks))])

        # 4) å†™å…¥ç´¢å¼•ï¼ˆå°½é‡é€‚é…ä¸åŒ Retriever å®ç°ï¼‰
        async def maybe_await(x):
            return await x if asyncio.iscoroutine(x) else x

        try:
            built_by = f"reader:{'mcp' if used_mcp else 'local'}; chunker:{CHUNK.name}"
            if hasattr(self.retriever, "rebuild_from_texts"):
                await maybe_await(self.retriever.rebuild_from_texts(
                    texts, metadatas, built_by=built_by, docs_sig=docs_sig
                ))
            elif hasattr(self.retriever, "rebuild"):
                # æ—§æ¥å£ï¼šæ— æ³•ä¼  built_by/docs_sigï¼Œåªèƒ½ç»´æŒæ—§è¡Œä¸º
                await maybe_await(self.retriever.rebuild(texts=texts, metadatas=metadatas))
            elif hasattr(self.retriever, "upsert_many"):
                await maybe_await(self.retriever.upsert_many(texts, metadatas, rebuild=True))
            elif hasattr(self.retriever, "add_texts"):
                await maybe_await(self.retriever.add_texts(texts, metadatas))
            else:
                return {"chunks": total_chunks, "built_by": built_by + "; no-op"}
        except Exception as e:
            return {"chunks": total_chunks, "built_by": f"error:{e}"}

        return {"chunks": total_chunks, "built_by": built_by}

    async def step(self, user_text: str, mode="qa"):
        self.memory.add_user(user_text)

        # --- æ–°å¢ï¼šrun æ¨¡å¼ï¼ˆä¸èµ° LLMï¼‰ ---
        if mode == "run":
            if not self.router:
                msg = "å·¥å…·ä¸å¯ç”¨ï¼šæœªè¿æ¥ MCPã€‚è¯·åœ¨é…ç½®ä¸­å¯ç”¨ code_serverã€‚"
                self.memory.add_assistant(msg)
                return msg
            try:
                msg = await _run_mode_dispatch(self.router, user_text)
            except Exception as e:
                msg = f"è¿è¡Œå¤±è´¥ï¼š{e}"
            self.memory.add_assistant(msg)
            return msg

        # 1) RAG æ£€ç´¢
        rag_ctx = []
        if self.rag_top_k and self.rag_top_k > 0:
            rag_ctx = await self.retriever.topk(user_text, self.rag_top_k)

        # 2) å·¥å…·è°ƒç”¨ï¼ˆä»…åœ¨ solve æ¨¡å¼ï¼šè‡ªåŠ¨è·¯ç”±â€œåšé¢˜â€ï¼‰
        tool_obs = None
        if mode == "solve" and self.router:
            txt = user_text.strip()
            try:
                # ---------- ç”»å›¾ï¼šç”»å›¾ <expr> ä» <start> åˆ° <end> ----------
                m = re.match(r"^ç”»å›¾\s+(.+?)\s+ä»\s+(-?\d+(?:\.\d+)?)\s+åˆ°\s+(-?\d+(?:\.\d+)?)\s*$", txt)
                if m:
                    expr, start, end = m.group(1), float(m.group(2)), float(m.group(3))
                    res = await _tools_call(self.router, "math.plot",
                                            {"expr": expr, "var": "x", "start": start, "end": end, "num": 600})
                    path = res.get("path") or res.get("image_path")
                    tool_obs = f"[math.plot] {json.dumps(res, ensure_ascii=False)}"
                    self.memory.add_assistant(f"âœ… å·²ç”Ÿæˆå›¾åƒï¼š{path}")

                # ---------- çŸ©é˜µä¹˜æ³• ----------
                if tool_obs is None:
                    m2 = re.match(r"^(?:çŸ©é˜µä¹˜æ³•|è®¡ç®—)\s+(\[.*\])\s*(?:\*|Ã—|x)\s*(\[.*\])\s*$",
                                  txt.replace(" ", ""))
                    if not m2:
                        m2 = re.match(r"^(?:çŸ©é˜µä¹˜æ³•|è®¡ç®—)\s+(\[.*\])\s*(?:\*|Ã—|x)\s*(\[.*\])\s*$", txt)
                    if m2:
                        A = _parse_matrix_side(m2.group(1))
                        B = _parse_matrix_side(m2.group(2))
                        res = await _tools_call(self.router, "math.matrix_multiply", {"A": A, "B": B})
                        tool_obs = f"[math.matrix_multiply] {json.dumps(res, ensure_ascii=False)}"
                        mat = res.get("matrix") or res.get("result")
                        shape = res.get("shape")
                        self.memory.add_assistant(f"âœ… çŸ©é˜µä¹˜æ³•ç»“æœï¼ˆshape={shape}ï¼‰ï¼š\n{mat}")

                # ---------- æ±‚å¯¼ ----------
                if tool_obs is None:
                    m3 = re.match(r"^å¯¹\s+(.+?)\s+æ±‚å¯¼\s*$", txt)
                    if m3:
                        expr = m3.group(1)
                        res = await _tools_call(self.router, "math.diff", {"expr": expr, "var": "x"})
                        tool_obs = f"[math.diff] {json.dumps(res, ensure_ascii=False)}"
                        self.memory.add_assistant(f"âˆ‚/âˆ‚x {expr} = {res.get('derivative')}")

                # ---------- ç§¯åˆ† ----------
                if tool_obs is None:
                    m4 = re.match(r"^å¯¹\s+(.+?)\s+ç§¯åˆ†\s*$", txt)
                    if m4:
                        expr = m4.group(1)
                        res = await _tools_call(self.router, "math.integrate", {"expr": expr, "var": "x"})
                        tool_obs = f"[math.integrate] {json.dumps(res, ensure_ascii=False)}"
                        self.memory.add_assistant(f"âˆ« {expr} dx = {res.get('integral')} + C")

                # ---------- è§£æ–¹ç¨‹ï¼ˆå…œåº•ï¼‰ ----------
                if tool_obs is None:
                    looks_like_equation = ("=" in txt) or ("è§£æ–¹ç¨‹" in txt) or ("æ±‚è§£" in txt)
                    if looks_like_equation:
                        res = await _tools_call(self.router, "math.solve_equation", {"expr": txt, "var": "x"})
                        tool_obs = f"[math.solve_equation] {json.dumps(res, ensure_ascii=False)}"
                        sols = res.get("solutions", [])
                        self.memory.add_assistant(f"è§£ï¼š{', '.join(map(str, sols)) if sols else '(æ— è§£æˆ–éä»£æ•°æ–¹ç¨‹)'}")
            except Exception as e:
                tool_obs = f"[tool_error] {e}"

        # 3) LLM ç”Ÿæˆ
        messages = build_messages(self.memory, rag_ctx, tool_obs, mode)
        reply = await self.llm.complete(messages)
        self.memory.add_assistant(reply)
        return reply
